{"ast":null,"code":"import { __assign } from \"tslib\";\nimport { invariant, newInvariantError } from \"../../utilities/globals/index.js\";\nimport { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\nimport { Kind } from \"graphql\";\nimport { getFragmentFromSelection, getDefaultValues, getOperationDefinition, getTypenameFromResult, makeReference, isField, resultKeyNameFromField, isReference, shouldInclude, cloneDeep, addTypenameToDocument, isNonEmptyArray, argumentsObjectFromField } from \"../../utilities/index.js\";\nimport { isArray, makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject, extractFragmentContext } from \"./helpers.js\";\nimport { canonicalStringify } from \"./object-canon.js\";\nimport { normalizeReadFieldOptions } from \"./policies.js\"; // Since there are only four possible combinations of context.clientOnly and\n// context.deferred values, we should need at most four \"flavors\" of any given\n// WriteContext. To avoid creating multiple copies of the same context, we cache\n// the contexts in the context.flavors Map (shared by all flavors) according to\n// their clientOnly and deferred values (always in that order).\n\nfunction getContextFlavor(context, clientOnly, deferred) {\n  var key = \"\".concat(clientOnly).concat(deferred);\n  var flavored = context.flavors.get(key);\n\n  if (!flavored) {\n    context.flavors.set(key, flavored = context.clientOnly === clientOnly && context.deferred === deferred ? context : __assign(__assign({}, context), {\n      clientOnly: clientOnly,\n      deferred: deferred\n    }));\n  }\n\n  return flavored;\n}\n\nvar StoreWriter =\n/** @class */\nfunction () {\n  function StoreWriter(cache, reader, fragments) {\n    this.cache = cache;\n    this.reader = reader;\n    this.fragments = fragments;\n  }\n\n  StoreWriter.prototype.writeToStore = function (store, _a) {\n    var _this = this;\n\n    var query = _a.query,\n        result = _a.result,\n        dataId = _a.dataId,\n        variables = _a.variables,\n        overwrite = _a.overwrite;\n    var operationDefinition = getOperationDefinition(query);\n    var merger = makeProcessedFieldsMerger();\n    variables = __assign(__assign({}, getDefaultValues(operationDefinition)), variables);\n\n    var context = __assign(__assign({\n      store: store,\n      written: Object.create(null),\n      merge: function (existing, incoming) {\n        return merger.merge(existing, incoming);\n      },\n      variables: variables,\n      varString: canonicalStringify(variables)\n    }, extractFragmentContext(query, this.fragments)), {\n      overwrite: !!overwrite,\n      incomingById: new Map(),\n      clientOnly: false,\n      deferred: false,\n      flavors: new Map()\n    });\n\n    var ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId: dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: {\n        map: new Map()\n      },\n      context: context\n    });\n\n    if (!isReference(ref)) {\n      throw newInvariantError(11, result);\n    } // So far, the store has not been modified, so now it's time to process\n    // context.incomingById and merge those incoming fields into context.store.\n\n\n    context.incomingById.forEach(function (_a, dataId) {\n      var storeObject = _a.storeObject,\n          mergeTree = _a.mergeTree,\n          fieldNodeSet = _a.fieldNodeSet;\n      var entityRef = makeReference(dataId);\n\n      if (mergeTree && mergeTree.map.size) {\n        var applied = _this.applyMerges(mergeTree, entityRef, storeObject, context);\n\n        if (isReference(applied)) {\n          // Assume References returned by applyMerges have already been merged\n          // into the store. See makeMergeObjectsFunction in policies.ts for an\n          // example of how this can happen.\n          return;\n        } // Otherwise, applyMerges returned a StoreObject, whose fields we should\n        // merge into the store (see store.merge statement below).\n\n\n        storeObject = applied;\n      }\n\n      if (globalThis.__DEV__ !== false && !context.overwrite) {\n        var fieldsWithSelectionSets_1 = Object.create(null);\n        fieldNodeSet.forEach(function (field) {\n          if (field.selectionSet) {\n            fieldsWithSelectionSets_1[field.name.value] = true;\n          }\n        });\n\n        var hasSelectionSet_1 = function (storeFieldName) {\n          return fieldsWithSelectionSets_1[fieldNameFromStoreName(storeFieldName)] === true;\n        };\n\n        var hasMergeFunction_1 = function (storeFieldName) {\n          var childTree = mergeTree && mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n\n        Object.keys(storeObject).forEach(function (storeFieldName) {\n          // If a merge function was defined for this field, trust that it\n          // did the right thing about (not) clobbering data. If the field\n          // has no selection set, it's a scalar field, so it doesn't need\n          // a merge function (even if it's an object, like JSON data).\n          if (hasSelectionSet_1(storeFieldName) && !hasMergeFunction_1(storeFieldName)) {\n            warnAboutDataLoss(entityRef, storeObject, storeFieldName, context.store);\n          }\n        });\n      }\n\n      store.merge(dataId, storeObject);\n    }); // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n\n    store.retain(ref.__ref);\n    return ref;\n  };\n\n  StoreWriter.prototype.processSelectionSet = function (_a) {\n    var _this = this;\n\n    var dataId = _a.dataId,\n        result = _a.result,\n        selectionSet = _a.selectionSet,\n        context = _a.context,\n        // This object allows processSelectionSet to report useful information\n    // to its callers without explicitly returning that information.\n    mergeTree = _a.mergeTree;\n    var policies = this.cache.policies; // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n\n    var incoming = Object.create(null); // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n\n    var typename = dataId && policies.rootTypenamesById[dataId] || getTypenameFromResult(result, selectionSet, context.fragmentMap) || dataId && context.store.get(dataId, \"__typename\");\n\n    if (\"string\" === typeof typename) {\n      incoming.__typename = typename;\n    } // This readField function will be passed as context.readField in the\n    // KeyFieldsContext object created within policies.identify (called below).\n    // In addition to reading from the existing context.store (thanks to the\n    // policies.readField(options, context) line at the very bottom), this\n    // version of readField can read from Reference objects that are currently\n    // pending in context.incomingById, which is important whenever keyFields\n    // need to be extracted from a child object that processSelectionSet has\n    // turned into a Reference.\n\n\n    var readField = function () {\n      var options = normalizeReadFieldOptions(arguments, incoming, context.variables);\n\n      if (isReference(options.from)) {\n        var info = context.incomingById.get(options.from.__ref);\n\n        if (info) {\n          var result_1 = policies.readField(__assign(__assign({}, options), {\n            from: info.storeObject\n          }), context);\n\n          if (result_1 !== void 0) {\n            return result_1;\n          }\n        }\n      }\n\n      return policies.readField(options, context);\n    };\n\n    var fieldNodeSet = new Set();\n    this.flattenFields(selectionSet, result, // This WriteContext will be the default context value for fields returned\n    // by the flattenFields method, but some fields may be assigned a modified\n    // context, depending on the presence of @client and other directives.\n    context, typename).forEach(function (context, field) {\n      var _a;\n\n      var resultFieldKey = resultKeyNameFromField(field);\n      var value = result[resultFieldKey];\n      fieldNodeSet.add(field);\n\n      if (value !== void 0) {\n        var storeFieldName = policies.getStoreFieldName({\n          typename: typename,\n          fieldName: field.name.value,\n          field: field,\n          variables: context.variables\n        });\n        var childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n        var incomingValue = _this.processFieldValue(value, field, // Reset context.clientOnly and context.deferred to their default\n        // values before processing nested selection sets.\n        field.selectionSet ? getContextFlavor(context, false, false) : context, childTree); // To determine if this field holds a child object with a merge function\n        // defined in its type policy (see PR #7070), we need to figure out the\n        // child object's __typename.\n\n\n        var childTypename = void 0; // The field's value can be an object that has a __typename only if the\n        // field has a selection set. Otherwise incomingValue is scalar.\n\n        if (field.selectionSet && (isReference(incomingValue) || storeValueIsStoreObject(incomingValue))) {\n          childTypename = readField(\"__typename\", incomingValue);\n        }\n\n        var merge = policies.getMergeFunction(typename, field.name.value, childTypename);\n\n        if (merge) {\n          childTree.info = {\n            // TODO Check compatibility against any existing childTree.field?\n            field: field,\n            typename: typename,\n            merge: merge\n          };\n        } else {\n          maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n        }\n\n        incoming = context.merge(incoming, (_a = {}, _a[storeFieldName] = incomingValue, _a));\n      } else if (globalThis.__DEV__ !== false && !context.clientOnly && !context.deferred && !addTypenameToDocument.added(field) && // If the field has a read function, it may be a synthetic field or\n      // provide a default value, so its absence from the written data should\n      // not be cause for alarm.\n      !policies.getReadFunction(typename, field.name.value)) {\n        globalThis.__DEV__ !== false && invariant.error(12, resultKeyNameFromField(field), result);\n      }\n    }); // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n\n    try {\n      var _b = policies.identify(result, {\n        typename: typename,\n        selectionSet: selectionSet,\n        fragmentMap: context.fragmentMap,\n        storeObject: incoming,\n        readField: readField\n      }),\n          id = _b[0],\n          keyObject = _b[1]; // If dataId was not provided, fall back to the id just generated by\n      // policies.identify.\n\n\n      dataId = dataId || id; // Write any key fields that were used during identification, even if\n      // they were not mentioned in the original query.\n\n      if (keyObject) {\n        // TODO Reverse the order of the arguments?\n        incoming = context.merge(incoming, keyObject);\n      }\n    } catch (e) {\n      // If dataId was provided, tolerate failure of policies.identify.\n      if (!dataId) throw e;\n    }\n\n    if (\"string\" === typeof dataId) {\n      var dataRef = makeReference(dataId); // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n\n      var sets = context.written[dataId] || (context.written[dataId] = []);\n      if (sets.indexOf(selectionSet) >= 0) return dataRef;\n      sets.push(selectionSet); // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n\n      if (this.reader && this.reader.isFresh(result, dataRef, selectionSet, context)) {\n        return dataRef;\n      }\n\n      var previous_1 = context.incomingById.get(dataId);\n\n      if (previous_1) {\n        previous_1.storeObject = context.merge(previous_1.storeObject, incoming);\n        previous_1.mergeTree = mergeMergeTrees(previous_1.mergeTree, mergeTree);\n        fieldNodeSet.forEach(function (field) {\n          return previous_1.fieldNodeSet.add(field);\n        });\n      } else {\n        context.incomingById.set(dataId, {\n          storeObject: incoming,\n          // Save a reference to mergeTree only if it is not empty, because\n          // empty MergeTrees may be recycled by maybeRecycleChildMergeTree and\n          // reused for entirely different parts of the result tree.\n          mergeTree: mergeTreeIsEmpty(mergeTree) ? void 0 : mergeTree,\n          fieldNodeSet: fieldNodeSet\n        });\n      }\n\n      return dataRef;\n    }\n\n    return incoming;\n  };\n\n  StoreWriter.prototype.processFieldValue = function (value, field, context, mergeTree) {\n    var _this = this;\n\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return globalThis.__DEV__ !== false ? cloneDeep(value) : value;\n    }\n\n    if (isArray(value)) {\n      return value.map(function (item, i) {\n        var value = _this.processFieldValue(item, field, context, getChildMergeTree(mergeTree, i));\n\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context: context,\n      mergeTree: mergeTree\n    });\n  }; // Implements https://spec.graphql.org/draft/#sec-Field-Collection, but with\n  // some additions for tracking @client and @defer directives.\n\n\n  StoreWriter.prototype.flattenFields = function (selectionSet, result, context, typename) {\n    if (typename === void 0) {\n      typename = getTypenameFromResult(result, selectionSet, context.fragmentMap);\n    }\n\n    var fieldMap = new Map();\n    var policies = this.cache.policies;\n    var limitingTrie = new Trie(false); // No need for WeakMap, since limitingTrie does not escape.\n\n    (function flatten(selectionSet, inheritedContext) {\n      var visitedNode = limitingTrie.lookup(selectionSet, // Because we take inheritedClientOnly and inheritedDeferred into\n      // consideration here (in addition to selectionSet), it's possible for\n      // the same selection set to be flattened more than once, if it appears\n      // in the query with different @client and/or @directive configurations.\n      inheritedContext.clientOnly, inheritedContext.deferred);\n      if (visitedNode.visited) return;\n      visitedNode.visited = true;\n      selectionSet.selections.forEach(function (selection) {\n        if (!shouldInclude(selection, context.variables)) return;\n        var clientOnly = inheritedContext.clientOnly,\n            deferred = inheritedContext.deferred;\n\n        if ( // Since the presence of @client or @defer on this field can only\n        // cause clientOnly or deferred to become true, we can skip the\n        // forEach loop if both clientOnly and deferred are already true.\n        !(clientOnly && deferred) && isNonEmptyArray(selection.directives)) {\n          selection.directives.forEach(function (dir) {\n            var name = dir.name.value;\n            if (name === \"client\") clientOnly = true;\n\n            if (name === \"defer\") {\n              var args = argumentsObjectFromField(dir, context.variables); // The @defer directive takes an optional args.if boolean\n              // argument, similar to @include(if: boolean). Note that\n              // @defer(if: false) does not make context.deferred false, but\n              // instead behaves as if there was no @defer directive.\n\n              if (!args || args.if !== false) {\n                deferred = true;\n              } // TODO In the future, we may want to record args.label using\n              // context.deferred, if a label is specified.\n\n            }\n          });\n        }\n\n        if (isField(selection)) {\n          var existing = fieldMap.get(selection);\n\n          if (existing) {\n            // If this field has been visited along another recursive path\n            // before, the final context should have clientOnly or deferred set\n            // to true only if *all* paths have the directive (hence the &&).\n            clientOnly = clientOnly && existing.clientOnly;\n            deferred = deferred && existing.deferred;\n          }\n\n          fieldMap.set(selection, getContextFlavor(context, clientOnly, deferred));\n        } else {\n          var fragment = getFragmentFromSelection(selection, context.lookupFragment);\n\n          if (!fragment && selection.kind === Kind.FRAGMENT_SPREAD) {\n            throw newInvariantError(13, selection.name.value);\n          }\n\n          if (fragment && policies.fragmentMatches(fragment, typename, result, context.variables)) {\n            flatten(fragment.selectionSet, getContextFlavor(context, clientOnly, deferred));\n          }\n        }\n      });\n    })(selectionSet, context);\n\n    return fieldMap;\n  };\n\n  StoreWriter.prototype.applyMerges = function (mergeTree, existing, incoming, context, getStorageArgs) {\n    var _a;\n\n    var _this = this;\n\n    if (mergeTree.map.size && !isReference(incoming)) {\n      var e_1 = // Items in the same position in different arrays are not\n      // necessarily related to each other, so when incoming is an array\n      // we process its elements as if there was no existing data.\n      !isArray(incoming) && ( // Likewise, existing must be either a Reference or a StoreObject\n      // in order for its fields to be safe to merge with the fields of\n      // the incoming object.\n      isReference(existing) || storeValueIsStoreObject(existing)) ? existing : void 0; // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n\n      var i_1 = incoming; // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n\n      if (e_1 && !getStorageArgs) {\n        getStorageArgs = [isReference(e_1) ? e_1.__ref : e_1];\n      } // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n\n\n      var changedFields_1;\n\n      var getValue_1 = function (from, name) {\n        return isArray(from) ? typeof name === \"number\" ? from[name] : void 0 : context.store.getFieldValue(from, String(name));\n      };\n\n      mergeTree.map.forEach(function (childTree, storeFieldName) {\n        var eVal = getValue_1(e_1, storeFieldName);\n        var iVal = getValue_1(i_1, storeFieldName); // If we have no incoming data, leave any existing data untouched.\n\n        if (void 0 === iVal) return;\n\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n\n        var aVal = _this.applyMerges(childTree, eVal, iVal, context, getStorageArgs);\n\n        if (aVal !== iVal) {\n          changedFields_1 = changedFields_1 || new Map();\n          changedFields_1.set(storeFieldName, aVal);\n        }\n\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields_1) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = isArray(i_1) ? i_1.slice(0) : __assign({}, i_1);\n        changedFields_1.forEach(function (value, name) {\n          incoming[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(existing, incoming, mergeTree.info, context, getStorageArgs && (_a = context.store).getStorage.apply(_a, getStorageArgs));\n    }\n\n    return incoming;\n  };\n\n  return StoreWriter;\n}();\n\nexport { StoreWriter };\nvar emptyMergeTreePool = [];\n\nfunction getChildMergeTree(_a, name) {\n  var map = _a.map;\n\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || {\n      map: new Map()\n    });\n  }\n\n  return map.get(name);\n}\n\nfunction mergeMergeTrees(left, right) {\n  if (left === right || !right || mergeTreeIsEmpty(right)) return left;\n  if (!left || mergeTreeIsEmpty(left)) return right;\n  var info = left.info && right.info ? __assign(__assign({}, left.info), right.info) : left.info || right.info;\n  var needToMergeMaps = left.map.size && right.map.size;\n  var map = needToMergeMaps ? new Map() : left.map.size ? left.map : right.map;\n  var merged = {\n    info: info,\n    map: map\n  };\n\n  if (needToMergeMaps) {\n    var remainingRightKeys_1 = new Set(right.map.keys());\n    left.map.forEach(function (leftTree, key) {\n      merged.map.set(key, mergeMergeTrees(leftTree, right.map.get(key)));\n      remainingRightKeys_1.delete(key);\n    });\n    remainingRightKeys_1.forEach(function (key) {\n      merged.map.set(key, mergeMergeTrees(right.map.get(key), left.map.get(key)));\n    });\n  }\n\n  return merged;\n}\n\nfunction mergeTreeIsEmpty(tree) {\n  return !tree || !(tree.info || tree.map.size);\n}\n\nfunction maybeRecycleChildMergeTree(_a, name) {\n  var map = _a.map;\n  var childTree = map.get(name);\n\n  if (childTree && mergeTreeIsEmpty(childTree)) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nvar warnings = new Set(); // Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\n\nfunction warnAboutDataLoss(existingRef, incomingObj, storeFieldName, store) {\n  var getChild = function (objOrRef) {\n    var child = store.getFieldValue(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  var existing = getChild(existingRef);\n  if (!existing) return;\n  var incoming = getChild(incomingObj);\n  if (!incoming) return; // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n\n  if (isReference(existing)) return; // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n\n  if (equal(existing, incoming)) return; // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n\n  if (Object.keys(existing).every(function (key) {\n    return store.getFieldValue(incoming, key) !== void 0;\n  })) {\n    return;\n  }\n\n  var parentType = store.getFieldValue(existingRef, \"__typename\") || store.getFieldValue(incomingObj, \"__typename\");\n  var fieldName = fieldNameFromStoreName(storeFieldName);\n  var typeDotName = \"\".concat(parentType, \".\").concat(fieldName); // Avoid warning more than once for the same type and field name.\n\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n  var childTypenames = []; // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n\n  if (!isArray(existing) && !isArray(incoming)) {\n    [existing, incoming].forEach(function (child) {\n      var typename = store.getFieldValue(child, \"__typename\");\n\n      if (typeof typename === \"string\" && !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  globalThis.__DEV__ !== false && invariant.warn(14, fieldName, parentType, childTypenames.length ? \"either ensure all objects of type \" + childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \" : \"\", typeDotName, existing, incoming);\n}","map":{"version":3,"sources":["../../../src/cache/inmemory/writeToStore.ts"],"names":[],"mappings":";AAAA,SAAS,SAAT,EAAoB,iBAApB,QAA6C,kCAA7C;AACA,SAAS,KAAT,QAAsB,eAAtB;AACA,SAAS,IAAT,QAAqB,WAArB;AAEA,SAAS,IAAT,QAAqB,SAArB;AASA,SACE,wBADF,EAEE,gBAFF,EAGE,sBAHF,EAIE,qBAJF,EAKE,aALF,EAME,OANF,EAOE,sBAPF,EAQE,WARF,EASE,aATF,EAUE,SAVF,EAWE,qBAXF,EAYE,eAZF,EAaE,wBAbF,QAcO,0BAdP;AAsBA,SACE,OADF,EAEE,yBAFF,EAGE,sBAHF,EAIE,uBAJF,EAKE,sBALF,QAMO,cANP;AAWA,SAAS,kBAAT,QAAmC,mBAAnC;AACA,SAAS,yBAAT,QAA0C,eAA1C,C,CAkCA;AACA;AACA;AACA;AACA;;AACA,SAAS,gBAAT,CACE,OADF,EAEE,UAFF,EAGE,QAHF,EAGgC;AAE9B,MAAM,GAAG,GAAG,GAAA,MAAA,CAAG,UAAH,EAAa,MAAb,CAAgB,QAAhB,CAAZ;AACA,MAAI,QAAQ,GAAG,OAAO,CAAC,OAAR,CAAgB,GAAhB,CAAoB,GAApB,CAAf;;AACA,MAAI,CAAC,QAAL,EAAe;AACb,IAAA,OAAO,CAAC,OAAR,CAAgB,GAAhB,CACE,GADF,EAEG,QAAQ,GACP,OAAO,CAAC,UAAR,KAAuB,UAAvB,IAAqC,OAAO,CAAC,QAAR,KAAqB,QAA1D,GACE,OADF,GAEC,QAAA,CAAA,QAAA,CAAA,EAAA,EACM,OADN,CAAA,EACa;AACV,MAAA,UAAU,EAAA,UADA;AAEV,MAAA,QAAQ,EAAA;AAFE,KADb,CALL;AAWD;;AACD,SAAO,QAAP;AACD;;AAUD,IAAA,WAAA;AAAA;AAAA,YAAA;AACE,WAAA,WAAA,CACkB,KADlB,EAEU,MAFV,EAGU,SAHV,EAGsD;AAFpC,SAAA,KAAA,GAAA,KAAA;AACR,SAAA,MAAA,GAAA,MAAA;AACA,SAAA,SAAA,GAAA,SAAA;AACN;;AAEG,EAAA,WAAA,CAAA,SAAA,CAAA,YAAA,GAAP,UACE,KADF,EAEE,EAFF,EAEqE;AAFrE,QAAA,KAAA,GAAA,IAAA;;QAEI,KAAK,GAAA,EAAA,CAAA,K;QAAE,MAAM,GAAA,EAAA,CAAA,M;QAAE,MAAM,GAAA,EAAA,CAAA,M;QAAE,SAAS,GAAA,EAAA,CAAA,S;QAAE,SAAS,GAAA,EAAA,CAAA,S;AAE7C,QAAM,mBAAmB,GAAG,sBAAsB,CAAC,KAAD,CAAlD;AACA,QAAM,MAAM,GAAG,yBAAyB,EAAxC;AAEA,IAAA,SAAS,GAAA,QAAA,CAAA,QAAA,CAAA,EAAA,EACJ,gBAAgB,CAAC,mBAAD,CADZ,CAAA,EAEJ,SAFI,CAAT;;AAKA,QAAM,OAAO,GAAA,QAAA,CAAA,QAAA,CAAA;AACX,MAAA,KAAK,EAAA,KADM;AAEX,MAAA,OAAO,EAAE,MAAM,CAAC,MAAP,CAAc,IAAd,CAFE;AAGX,MAAA,KAAK,EAAA,UAAI,QAAJ,EAAiB,QAAjB,EAA4B;AAC/B,eAAO,MAAM,CAAC,KAAP,CAAa,QAAb,EAAuB,QAAvB,CAAP;AACD,OALU;AAMX,MAAA,SAAS,EAAA,SANE;AAOX,MAAA,SAAS,EAAE,kBAAkB,CAAC,SAAD;AAPlB,KAAA,EAQR,sBAAsB,CAAC,KAAD,EAAQ,KAAK,SAAb,CARd,CAAA,EAQqC;AAChD,MAAA,SAAS,EAAE,CAAC,CAAC,SADmC;AAEhD,MAAA,YAAY,EAAE,IAAI,GAAJ,EAFkC;AAGhD,MAAA,UAAU,EAAE,KAHoC;AAIhD,MAAA,QAAQ,EAAE,KAJsC;AAKhD,MAAA,OAAO,EAAE,IAAI,GAAJ;AALuC,KARrC,CAAb;;AAgBA,QAAM,GAAG,GAAG,KAAK,mBAAL,CAAyB;AACnC,MAAA,MAAM,EAAE,MAAM,IAAI,MAAM,CAAC,MAAP,CAAc,IAAd,CADiB;AAEnC,MAAA,MAAM,EAAA,MAF6B;AAGnC,MAAA,YAAY,EAAE,mBAAmB,CAAC,YAHC;AAInC,MAAA,SAAS,EAAE;AAAE,QAAA,GAAG,EAAE,IAAI,GAAJ;AAAP,OAJwB;AAKnC,MAAA,OAAO,EAAA;AAL4B,KAAzB,CAAZ;;AAQA,QAAI,CAAC,WAAW,CAAC,GAAD,CAAhB,EAAuB;AACrB,YAAM,iBAAiB,CAAC,EAAD,EAAC,MAAD,CAAvB;AACD,KApCkE,CAsCnE;AACA;;;AACA,IAAA,OAAO,CAAC,YAAR,CAAqB,OAArB,CACE,UAAC,EAAD,EAA2C,MAA3C,EAAiD;UAA9C,WAAW,GAAA,EAAA,CAAA,W;UAAE,SAAS,GAAA,EAAA,CAAA,S;UAAE,YAAY,GAAA,EAAA,CAAA,Y;AACrC,UAAM,SAAS,GAAG,aAAa,CAAC,MAAD,CAA/B;;AAEA,UAAI,SAAS,IAAI,SAAS,CAAC,GAAV,CAAc,IAA/B,EAAqC;AACnC,YAAM,OAAO,GAAG,KAAI,CAAC,WAAL,CACd,SADc,EAEd,SAFc,EAGd,WAHc,EAId,OAJc,CAAhB;;AAMA,YAAI,WAAW,CAAC,OAAD,CAAf,EAA0B;AACxB;AACA;AACA;AACA;AACD,SAZkC,CAanC;AACA;;;AACA,QAAA,WAAW,GAAG,OAAd;AACD;;AAED,UAAI,UAAO,CAAI,OAAX,KAAoB,KAApB,IAAgC,CAAA,OAAA,CAAA,SAApC,EAAoC;AAClC,YAAM,yBAAuB,GAC3B,MAAM,CAAC,MAAP,CAAc,IAAd,CADF;AAEA,QAAA,YAAY,CAAC,OAAb,CAAqB,UAAC,KAAD,EAAM;AACzB,cAAI,KAAK,CAAC,YAAV,EAAwB;AACtB,YAAA,yBAAuB,CAAC,KAAK,CAAC,IAAN,CAAW,KAAZ,CAAvB,GAA4C,IAA5C;AACD;AACF,SAJD;;AAMA,YAAM,iBAAe,GAAG,UAAC,cAAD,EAAuB;AAC7C,iBAAA,yBAAuB,CAAC,sBAAsB,CAAC,cAAD,CAAvB,CAAvB,KACA,IADA;AACI,SAFN;;AAIA,YAAM,kBAAgB,GAAG,UAAC,cAAD,EAAuB;AAC9C,cAAM,SAAS,GAAG,SAAS,IAAI,SAAS,CAAC,GAAV,CAAc,GAAd,CAAkB,cAAlB,CAA/B;AACA,iBAAO,OAAO,CAAC,SAAS,IAAI,SAAS,CAAC,IAAvB,IAA+B,SAAS,CAAC,IAAV,CAAe,KAA/C,CAAd;AACD,SAHD;;AAKA,QAAA,MAAM,CAAC,IAAP,CAAY,WAAZ,EAAyB,OAAzB,CAAiC,UAAC,cAAD,EAAe;AAC9C;AACA;AACA;AACA;AACA,cACE,iBAAe,CAAC,cAAD,CAAf,IACA,CAAC,kBAAgB,CAAC,cAAD,CAFnB,EAGE;AACA,YAAA,iBAAiB,CACf,SADe,EAEf,WAFe,EAGf,cAHe,EAIf,OAAO,CAAC,KAJO,CAAjB;AAMD;AACF,SAhBD;AAiBD;;AAED,MAAA,KAAK,CAAC,KAAN,CAAY,MAAZ,EAAoB,WAApB;AACD,KA5DH,EAxCmE,CAuGnE;AACA;AACA;AACA;AACA;;AACA,IAAA,KAAK,CAAC,MAAN,CAAa,GAAG,CAAC,KAAjB;AAEA,WAAO,GAAP;AACD,GAjHM;;AAmHC,EAAA,WAAA,CAAA,SAAA,CAAA,mBAAA,GAAR,UAA4B,EAA5B,EAQ6B;AAR7B,QAAA,KAAA,GAAA,IAAA;;QACE,MAAM,GAAA,EAAA,CAAA,M;QACN,MAAM,GAAA,EAAA,CAAA,M;QACN,YAAY,GAAA,EAAA,CAAA,Y;QACZ,OAAO,GAAA,EAAA,CAAA,O;QACP;AACA;AACA,IAAA,SAAS,GAAA,EAAA,CAAA,S;AAED,QAAA,QAAQ,GAAK,KAAK,KAAL,CAAL,QAAR,CADmB,CAG3B;AACA;;AACA,QAAI,QAAQ,GAAgB,MAAM,CAAC,MAAP,CAAc,IAAd,CAA5B,CAL2B,CAO3B;AACA;AACA;;AACA,QAAM,QAAQ,GACX,MAAM,IAAI,QAAQ,CAAC,iBAAT,CAA2B,MAA3B,CAAX,IACA,qBAAqB,CAAC,MAAD,EAAS,YAAT,EAAuB,OAAO,CAAC,WAA/B,CADrB,IAEC,MAAM,IAAK,OAAO,CAAC,KAAR,CAAc,GAAd,CAAkB,MAAlB,EAA0B,YAA1B,CAHd;;AAKA,QAAI,aAAa,OAAO,QAAxB,EAAkC;AAChC,MAAA,QAAQ,CAAC,UAAT,GAAsB,QAAtB;AACD,KAjB0B,CAmB3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,QAAM,SAAS,GAAsB,YAAA;AACnC,UAAM,OAAO,GAAG,yBAAyB,CACvC,SADuC,EAEvC,QAFuC,EAGvC,OAAO,CAAC,SAH+B,CAAzC;;AAMA,UAAI,WAAW,CAAC,OAAO,CAAC,IAAT,CAAf,EAA+B;AAC7B,YAAM,IAAI,GAAG,OAAO,CAAC,YAAR,CAAqB,GAArB,CAAyB,OAAO,CAAC,IAAR,CAAa,KAAtC,CAAb;;AACA,YAAI,IAAJ,EAAU;AACR,cAAM,QAAM,GAAG,QAAQ,CAAC,SAAT,CAAkB,QAAA,CAAA,QAAA,CAAA,EAAA,EAE1B,OAF0B,CAAA,EAEnB;AACV,YAAA,IAAI,EAAE,IAAI,CAAC;AADD,WAFmB,CAAlB,EAKb,OALa,CAAf;;AAQA,cAAI,QAAM,KAAK,KAAK,CAApB,EAAuB;AACrB,mBAAO,QAAP;AACD;AACF;AACF;;AAED,aAAO,QAAQ,CAAC,SAAT,CAAmB,OAAnB,EAA4B,OAA5B,CAAP;AACD,KAzBD;;AA2BA,QAAM,YAAY,GAAG,IAAI,GAAJ,EAArB;AAEA,SAAK,aAAL,CACE,YADF,EAEE,MAFF,EAGE;AACA;AACA;AACA,IAAA,OANF,EAOE,QAPF,EAQE,OARF,CAQU,UAAC,OAAD,EAAU,KAAV,EAAe;;;AACvB,UAAM,cAAc,GAAG,sBAAsB,CAAC,KAAD,CAA7C;AACA,UAAM,KAAK,GAAG,MAAM,CAAC,cAAD,CAApB;AAEA,MAAA,YAAY,CAAC,GAAb,CAAiB,KAAjB;;AAEA,UAAI,KAAK,KAAK,KAAK,CAAnB,EAAsB;AACpB,YAAM,cAAc,GAAG,QAAQ,CAAC,iBAAT,CAA2B;AAChD,UAAA,QAAQ,EAAA,QADwC;AAEhD,UAAA,SAAS,EAAE,KAAK,CAAC,IAAN,CAAW,KAF0B;AAGhD,UAAA,KAAK,EAAA,KAH2C;AAIhD,UAAA,SAAS,EAAE,OAAO,CAAC;AAJ6B,SAA3B,CAAvB;AAOA,YAAM,SAAS,GAAG,iBAAiB,CAAC,SAAD,EAAY,cAAZ,CAAnC;;AAEA,YAAI,aAAa,GAAG,KAAI,CAAC,iBAAL,CAClB,KADkB,EAElB,KAFkB,EAGlB;AACA;AACA,QAAA,KAAK,CAAC,YAAN,GACE,gBAAgB,CAAC,OAAD,EAAU,KAAV,EAAiB,KAAjB,CADlB,GAEE,OAPgB,EAQlB,SARkB,CAApB,CAVoB,CAqBpB;AACA;AACA;;;AACA,YAAI,aAAa,GAAA,KAAA,CAAjB,CAxBoB,CA0BpB;AACA;;AACA,YACE,KAAK,CAAC,YAAN,KACC,WAAW,CAAC,aAAD,CAAX,IAA8B,uBAAuB,CAAC,aAAD,CADtD,CADF,EAGE;AACA,UAAA,aAAa,GAAG,SAAS,CAAS,YAAT,EAAuB,aAAvB,CAAzB;AACD;;AAED,YAAM,KAAK,GAAG,QAAQ,CAAC,gBAAT,CACZ,QADY,EAEZ,KAAK,CAAC,IAAN,CAAW,KAFC,EAGZ,aAHY,CAAd;;AAMA,YAAI,KAAJ,EAAW;AACT,UAAA,SAAS,CAAC,IAAV,GAAiB;AACf;AACA,YAAA,KAAK,EAAA,KAFU;AAGf,YAAA,QAAQ,EAAA,QAHO;AAIf,YAAA,KAAK,EAAA;AAJU,WAAjB;AAMD,SAPD,MAOO;AACL,UAAA,0BAA0B,CAAC,SAAD,EAAY,cAAZ,CAA1B;AACD;;AAED,QAAA,QAAQ,GAAG,OAAO,CAAC,KAAR,CAAc,QAAd,GAAsB,EAAA,GAAA,EAAA,EAC/B,EAAA,CAAC,cAAD,CAAA,GAAkB,aADa,EAE/B,EAFS,EAAX;AAGD,OAvDD,MAuDO,IACL,UAAO,CAAA,OAAP,KAAO,KAAP,IACA,CAAC,OAAO,CAAC,UADT,IAEA,CAAC,OAAO,CAAC,QAFT,IAGA,CAAC,qBAAqB,CAAC,KAAtB,CAA4B,KAA5B,CAHD,IAIA;AACA;AACA;AACA,OAAC,QAAQ,CAAC,eAAT,CAAyB,QAAzB,EAAmC,KAAK,CAAC,IAAN,CAAW,KAA9C,CARI,EASL;AACA,QAAA,UAAU,CAAA,OAAV,KACE,KADF,IACE,SAAA,CAAA,KAAA,CAAA,EAAA,EAAA,sBACA,CAAA,KAAA,CADA,EACA,MADA,CADF;AAKD;AACF,KArFD,EAxD2B,CA+I3B;AACA;;AACA,QAAI;AACI,UAAA,EAAA,GAAkB,QAAQ,CAAC,QAAT,CAAkB,MAAlB,EAA0B;AAChD,QAAA,QAAQ,EAAA,QADwC;AAEhD,QAAA,YAAY,EAAA,YAFoC;AAGhD,QAAA,WAAW,EAAE,OAAO,CAAC,WAH2B;AAIhD,QAAA,WAAW,EAAE,QAJmC;AAKhD,QAAA,SAAS,EAAA;AALuC,OAA1B,CAAlB;AAAA,UAAC,EAAE,GAAA,EAAA,CAAA,CAAA,CAAH;AAAA,UAAK,SAAS,GAAA,EAAA,CAAA,CAAA,CAAd,CADJ,CASF;AACA;;;AACA,MAAA,MAAM,GAAG,MAAM,IAAI,EAAnB,CAXE,CAaF;AACA;;AACA,UAAI,SAAJ,EAAe;AACb;AACA,QAAA,QAAQ,GAAG,OAAO,CAAC,KAAR,CAAc,QAAd,EAAwB,SAAxB,CAAX;AACD;AACF,KAnBD,CAmBE,OAAO,CAAP,EAAU;AACV;AACA,UAAI,CAAC,MAAL,EAAa,MAAM,CAAN;AACd;;AAED,QAAI,aAAa,OAAO,MAAxB,EAAgC;AAC9B,UAAM,OAAO,GAAG,aAAa,CAAC,MAAD,CAA7B,CAD8B,CAG9B;AACA;AACA;AACA;AACA;;AACA,UAAM,IAAI,GAAG,OAAO,CAAC,OAAR,CAAgB,MAAhB,MAA4B,OAAO,CAAC,OAAR,CAAgB,MAAhB,IAA0B,EAAtD,CAAb;AACA,UAAI,IAAI,CAAC,OAAL,CAAa,YAAb,KAA8B,CAAlC,EAAqC,OAAO,OAAP;AACrC,MAAA,IAAI,CAAC,IAAL,CAAU,YAAV,EAV8B,CAY9B;AACA;AACA;AACA;AACA;;AACA,UACE,KAAK,MAAL,IACA,KAAK,MAAL,CAAY,OAAZ,CAAoB,MAApB,EAA4B,OAA5B,EAAqC,YAArC,EAAmD,OAAnD,CAFF,EAGE;AACA,eAAO,OAAP;AACD;;AAED,UAAM,UAAQ,GAAG,OAAO,CAAC,YAAR,CAAqB,GAArB,CAAyB,MAAzB,CAAjB;;AACA,UAAI,UAAJ,EAAc;AACZ,QAAA,UAAQ,CAAC,WAAT,GAAuB,OAAO,CAAC,KAAR,CAAc,UAAQ,CAAC,WAAvB,EAAoC,QAApC,CAAvB;AACA,QAAA,UAAQ,CAAC,SAAT,GAAqB,eAAe,CAAC,UAAQ,CAAC,SAAV,EAAqB,SAArB,CAApC;AACA,QAAA,YAAY,CAAC,OAAb,CAAqB,UAAC,KAAD,EAAM;AAAK,iBAAA,UAAQ,CAAC,YAAT,CAAsB,GAAtB,CAAA,KAAA,CAAA;AAAgC,SAAhE;AACD,OAJD,MAIO;AACL,QAAA,OAAO,CAAC,YAAR,CAAqB,GAArB,CAAyB,MAAzB,EAAiC;AAC/B,UAAA,WAAW,EAAE,QADkB;AAE/B;AACA;AACA;AACA,UAAA,SAAS,EAAE,gBAAgB,CAAC,SAAD,CAAhB,GAA8B,KAAK,CAAnC,GAAuC,SALnB;AAM/B,UAAA,YAAY,EAAA;AANmB,SAAjC;AAQD;;AAED,aAAO,OAAP;AACD;;AAED,WAAO,QAAP;AACD,GA7NO;;AA+NA,EAAA,WAAA,CAAA,SAAA,CAAA,iBAAA,GAAR,UACE,KADF,EAEE,KAFF,EAGE,OAHF,EAIE,SAJF,EAIsB;AAJtB,QAAA,KAAA,GAAA,IAAA;;AAME,QAAI,CAAC,KAAK,CAAC,YAAP,IAAuB,KAAK,KAAK,IAArC,EAA2C;AACzC;AACA;AACA;AACA,aAAO,UAAU,CAAA,OAAV,KAAoB,KAApB,GAA6B,SAAM,CAAA,KAAA,CAAnC,GAAmC,KAA1C;AACD;;AAED,QAAI,OAAO,CAAC,KAAD,CAAX,EAAoB;AAClB,aAAO,KAAK,CAAC,GAAN,CAAU,UAAC,IAAD,EAAO,CAAP,EAAQ;AACvB,YAAM,KAAK,GAAG,KAAI,CAAC,iBAAL,CACZ,IADY,EAEZ,KAFY,EAGZ,OAHY,EAIZ,iBAAiB,CAAC,SAAD,EAAY,CAAZ,CAJL,CAAd;;AAMA,QAAA,0BAA0B,CAAC,SAAD,EAAY,CAAZ,CAA1B;AACA,eAAO,KAAP;AACD,OATM,CAAP;AAUD;;AAED,WAAO,KAAK,mBAAL,CAAyB;AAC9B,MAAA,MAAM,EAAE,KADsB;AAE9B,MAAA,YAAY,EAAE,KAAK,CAAC,YAFU;AAG9B,MAAA,OAAO,EAAA,OAHuB;AAI9B,MAAA,SAAS,EAAA;AAJqB,KAAzB,CAAP;AAMD,GAhCO,CAzVV,CA2XE;AACA;;;AACQ,EAAA,WAAA,CAAA,SAAA,CAAA,aAAA,GAAR,UAWE,YAXF,EAYE,MAZF,EAaE,OAbF,EAcE,QAdF,EAc6E;AAA3E,QAAA,QAAA,KAAA,KAAA,CAAA,EAAA;AAAA,MAAA,QAAA,GAAW,qBAAqB,CAAC,MAAD,EAAS,YAAT,EAAuB,OAAO,CAAC,WAA/B,CAAhC;AAA2E;;AAE3E,QAAM,QAAQ,GAAG,IAAI,GAAJ,EAAjB;AACQ,QAAA,QAAQ,GAAK,KAAK,KAAL,CAAL,QAAR;AAER,QAAM,YAAY,GAAG,IAAI,IAAJ,CAUlB,KAVkB,CAArB,CAL2E,CAehE;;AAEX,KAAC,SAAS,OAAT,CAEC,YAFD,EAGC,gBAHD,EAG2B;AAE1B,UAAM,WAAW,GAAG,YAAY,CAAC,MAAb,CAClB,YADkB,EAElB;AACA;AACA;AACA;AACA,MAAA,gBAAgB,CAAC,UANC,EAOlB,gBAAgB,CAAC,QAPC,CAApB;AASA,UAAI,WAAW,CAAC,OAAhB,EAAyB;AACzB,MAAA,WAAW,CAAC,OAAZ,GAAsB,IAAtB;AAEA,MAAA,YAAY,CAAC,UAAb,CAAwB,OAAxB,CAAgC,UAAC,SAAD,EAAU;AACxC,YAAI,CAAC,aAAa,CAAC,SAAD,EAAY,OAAO,CAAC,SAApB,CAAlB,EAAkD;AAE5C,YAAA,UAAU,GAAe,gBAAgB,CAA/B,UAAV;AAAA,YAAY,QAAQ,GAAK,gBAAgB,CAArB,QAApB;;AACN,aACE;AACA;AACA;AACA,UAAE,UAAU,IAAI,QAAhB,KACA,eAAe,CAAC,SAAS,CAAC,UAAX,CALjB,EAME;AACA,UAAA,SAAS,CAAC,UAAV,CAAqB,OAArB,CAA6B,UAAC,GAAD,EAAI;AAC/B,gBAAM,IAAI,GAAG,GAAG,CAAC,IAAJ,CAAS,KAAtB;AACA,gBAAI,IAAI,KAAK,QAAb,EAAuB,UAAU,GAAG,IAAb;;AACvB,gBAAI,IAAI,KAAK,OAAb,EAAsB;AACpB,kBAAM,IAAI,GAAG,wBAAwB,CAAC,GAAD,EAAM,OAAO,CAAC,SAAd,CAArC,CADoB,CAEpB;AACA;AACA;AACA;;AACA,kBAAI,CAAC,IAAD,IAAU,IAAyB,CAAC,EAA1B,KAAiC,KAA/C,EAAsD;AACpD,gBAAA,QAAQ,GAAG,IAAX;AACD,eARmB,CASpB;AACA;;AACD;AACF,WAfD;AAgBD;;AAED,YAAI,OAAO,CAAC,SAAD,CAAX,EAAwB;AACtB,cAAM,QAAQ,GAAG,QAAQ,CAAC,GAAT,CAAa,SAAb,CAAjB;;AACA,cAAI,QAAJ,EAAc;AACZ;AACA;AACA;AACA,YAAA,UAAU,GAAG,UAAU,IAAI,QAAQ,CAAC,UAApC;AACA,YAAA,QAAQ,GAAG,QAAQ,IAAI,QAAQ,CAAC,QAAhC;AACD;;AAED,UAAA,QAAQ,CAAC,GAAT,CACE,SADF,EAEE,gBAAgB,CAAC,OAAD,EAAU,UAAV,EAAsB,QAAtB,CAFlB;AAID,SAdD,MAcO;AACL,cAAM,QAAQ,GAAG,wBAAwB,CACvC,SADuC,EAEvC,OAAO,CAAC,cAF+B,CAAzC;;AAKA,cAAI,CAAC,QAAD,IAAa,SAAS,CAAC,IAAV,KAAmB,IAAI,CAAC,eAAzC,EAA0D;AACxD,kBAAM,iBAAiB,CACrB,EADqB,EACrB,SAAA,CAAA,IAAA,CAAA,KADqB,CAAvB;AAID;;AAED,cACE,QAAQ,IACR,QAAQ,CAAC,eAAT,CACE,QADF,EAEE,QAFF,EAGE,MAHF,EAIE,OAAO,CAAC,SAJV,CAFF,EAQE;AACA,YAAA,OAAO,CACL,QAAQ,CAAC,YADJ,EAEL,gBAAgB,CAAC,OAAD,EAAU,UAAV,EAAsB,QAAtB,CAFX,CAAP;AAID;AACF;AACF,OAvED;AAwED,KAzFD,EAyFG,YAzFH,EAyFiB,OAzFjB;;AA2FA,WAAO,QAAP;AACD,GA3HO;;AA6HA,EAAA,WAAA,CAAA,SAAA,CAAA,WAAA,GAAR,UACE,SADF,EAEE,QAFF,EAGE,QAHF,EAIE,OAJF,EAKE,cALF,EAKwD;;;AALxD,QAAA,KAAA,GAAA,IAAA;;AAOE,QAAI,SAAS,CAAC,GAAV,CAAc,IAAd,IAAsB,CAAC,WAAW,CAAC,QAAD,CAAtC,EAAkD;AAChD,UAAM,GAAC,GACL;AACA;AACA;AAEE,OAAC,OAAO,CAAC,QAAD,CAAR,MACA;AACA;AACA;AACC,MAAA,WAAW,CAAC,QAAD,CAAX,IAAyB,uBAAuB,CAAC,QAAD,CAJjD,CADF,GAOE,QAPF,GAQE,KAAK,CAZT,CADgD,CAehD;AACA;AACA;;AACA,UAAM,GAAC,GAAG,QAAV,CAlBgD,CAoBhD;AACA;AACA;AACA;;AACA,UAAI,GAAC,IAAI,CAAC,cAAV,EAA0B;AACxB,QAAA,cAAc,GAAG,CAAC,WAAW,CAAC,GAAD,CAAX,GAAiB,GAAC,CAAC,KAAnB,GAA2B,GAA5B,CAAjB;AACD,OA1B+C,CA4BhD;AACA;AACA;AACA;AACA;;;AACA,UAAI,eAAJ;;AAEA,UAAM,UAAQ,GAAG,UACf,IADe,EAEf,IAFe,EAEM;AAErB,eACE,OAAO,CAAC,IAAD,CAAP,GACE,OAAO,IAAP,KAAgB,QAAhB,GACE,IAAI,CAAC,IAAD,CADN,GAEE,KAAK,CAHT,GAIE,OAAO,CAAC,KAAR,CAAc,aAAd,CAA4B,IAA5B,EAAkC,MAAM,CAAC,IAAD,CAAxC,CALJ;AAOD,OAXD;;AAaA,MAAA,SAAS,CAAC,GAAV,CAAc,OAAd,CAAsB,UAAC,SAAD,EAAY,cAAZ,EAA0B;AAC9C,YAAM,IAAI,GAAG,UAAQ,CAAC,GAAD,EAAI,cAAJ,CAArB;AACA,YAAM,IAAI,GAAG,UAAQ,CAAC,GAAD,EAAI,cAAJ,CAArB,CAF8C,CAG9C;;AACA,YAAI,KAAK,CAAL,KAAW,IAAf,EAAqB;;AACrB,YAAI,cAAJ,EAAoB;AAClB,UAAA,cAAc,CAAC,IAAf,CAAoB,cAApB;AACD;;AACD,YAAM,IAAI,GAAG,KAAI,CAAC,WAAL,CACX,SADW,EAEX,IAFW,EAGX,IAHW,EAIX,OAJW,EAKX,cALW,CAAb;;AAOA,YAAI,IAAI,KAAK,IAAb,EAAmB;AACjB,UAAA,eAAa,GAAG,eAAa,IAAI,IAAI,GAAJ,EAAjC;AACA,UAAA,eAAa,CAAC,GAAd,CAAkB,cAAlB,EAAkC,IAAlC;AACD;;AACD,YAAI,cAAJ,EAAoB;AAClB,UAAA,SAAS,CAAC,cAAc,CAAC,GAAf,OAAyB,cAA1B,CAAT;AACD;AACF,OAtBD;;AAwBA,UAAI,eAAJ,EAAmB;AACjB;AACA,QAAA,QAAQ,GAAI,OAAO,CAAC,GAAD,CAAP,GAAa,GAAC,CAAC,KAAF,CAAQ,CAAR,CAAb,GAAyB,QAAA,CAAA,EAAA,EAAM,GAAN,CAArC;AACA,QAAA,eAAa,CAAC,OAAd,CAAsB,UAAC,KAAD,EAAQ,IAAR,EAAY;AAC/B,UAAA,QAAgB,CAAC,IAAD,CAAhB,GAAyB,KAAzB;AACF,SAFD;AAGD;AACF;;AAED,QAAI,SAAS,CAAC,IAAd,EAAoB;AAClB,aAAO,KAAK,KAAL,CAAW,QAAX,CAAoB,gBAApB,CACL,QADK,EAEL,QAFK,EAGL,SAAS,CAAC,IAHL,EAIL,OAJK,EAKL,cAAc,IAAI,CAAA,EAAA,GAAA,OAAO,CAAC,KAAR,EAAc,UAAd,CAAwB,KAAxB,CAAwB,EAAxB,EAA4B,cAA5B,CALb,CAAP;AAOD;;AAED,WAAO,QAAP;AACD,GAnGO;;AAoGV,SAAA,WAAA;AAAC,CA9lBD,EAAA;;;AAgmBA,IAAM,kBAAkB,GAAgB,EAAxC;;AAEA,SAAS,iBAAT,CACE,EADF,EAEE,IAFF,EAEuB;MADnB,GAAG,GAAA,EAAA,CAAA,G;;AAGL,MAAI,CAAC,GAAG,CAAC,GAAJ,CAAQ,IAAR,CAAL,EAAoB;AAClB,IAAA,GAAG,CAAC,GAAJ,CAAQ,IAAR,EAAc,kBAAkB,CAAC,GAAnB,MAA4B;AAAE,MAAA,GAAG,EAAE,IAAI,GAAJ;AAAP,KAA1C;AACD;;AACD,SAAO,GAAG,CAAC,GAAJ,CAAQ,IAAR,CAAP;AACD;;AAED,SAAS,eAAT,CACE,IADF,EAEE,KAFF,EAE8B;AAE5B,MAAI,IAAI,KAAK,KAAT,IAAkB,CAAC,KAAnB,IAA4B,gBAAgB,CAAC,KAAD,CAAhD,EAAyD,OAAO,IAAP;AACzD,MAAI,CAAC,IAAD,IAAS,gBAAgB,CAAC,IAAD,CAA7B,EAAqC,OAAO,KAAP;AAErC,MAAM,IAAI,GACR,IAAI,CAAC,IAAL,IAAa,KAAK,CAAC,IAAnB,GAAyB,QAAA,CAAA,QAAA,CAAA,EAAA,EAElB,IAAI,CAAC,IAFa,CAAA,EAGlB,KAAK,CAAC,IAHY,CAAzB,GAKE,IAAI,CAAC,IAAL,IAAa,KAAK,CAAC,IANvB;AAQA,MAAM,eAAe,GAAG,IAAI,CAAC,GAAL,CAAS,IAAT,IAAiB,KAAK,CAAC,GAAN,CAAU,IAAnD;AACA,MAAM,GAAG,GACP,eAAe,GAAG,IAAI,GAAJ,EAAH,GACb,IAAI,CAAC,GAAL,CAAS,IAAT,GAAgB,IAAI,CAAC,GAArB,GACA,KAAK,CAAC,GAHV;AAKA,MAAM,MAAM,GAAG;AAAE,IAAA,IAAI,EAAA,IAAN;AAAQ,IAAA,GAAG,EAAA;AAAX,GAAf;;AAEA,MAAI,eAAJ,EAAqB;AACnB,QAAM,oBAAkB,GAAG,IAAI,GAAJ,CAAQ,KAAK,CAAC,GAAN,CAAU,IAAV,EAAR,CAA3B;AAEA,IAAA,IAAI,CAAC,GAAL,CAAS,OAAT,CAAiB,UAAC,QAAD,EAAW,GAAX,EAAc;AAC7B,MAAA,MAAM,CAAC,GAAP,CAAW,GAAX,CAAe,GAAf,EAAoB,eAAe,CAAC,QAAD,EAAW,KAAK,CAAC,GAAN,CAAU,GAAV,CAAc,GAAd,CAAX,CAAnC;AACA,MAAA,oBAAkB,CAAC,MAAnB,CAA0B,GAA1B;AACD,KAHD;AAKA,IAAA,oBAAkB,CAAC,OAAnB,CAA2B,UAAC,GAAD,EAAI;AAC7B,MAAA,MAAM,CAAC,GAAP,CAAW,GAAX,CACE,GADF,EAEE,eAAe,CAAC,KAAK,CAAC,GAAN,CAAU,GAAV,CAAc,GAAd,CAAD,EAAqB,IAAI,CAAC,GAAL,CAAS,GAAT,CAAa,GAAb,CAArB,CAFjB;AAID,KALD;AAMD;;AAED,SAAO,MAAP;AACD;;AAED,SAAS,gBAAT,CAA0B,IAA1B,EAAqD;AACnD,SAAO,CAAC,IAAD,IAAS,EAAE,IAAI,CAAC,IAAL,IAAa,IAAI,CAAC,GAAL,CAAS,IAAxB,CAAhB;AACD;;AAED,SAAS,0BAAT,CAAoC,EAApC,EAAwD,IAAxD,EAA6E;MAAvC,GAAG,GAAA,EAAA,CAAA,G;AACvC,MAAM,SAAS,GAAG,GAAG,CAAC,GAAJ,CAAQ,IAAR,CAAlB;;AACA,MAAI,SAAS,IAAI,gBAAgB,CAAC,SAAD,CAAjC,EAA8C;AAC5C,IAAA,kBAAkB,CAAC,IAAnB,CAAwB,SAAxB;AACA,IAAA,GAAG,CAAC,MAAJ,CAAW,IAAX;AACD;AACF;;AAED,IAAM,QAAQ,GAAG,IAAI,GAAJ,EAAjB,C,CAEA;AACA;;AACA,SAAS,iBAAT,CACE,WADF,EAEE,WAFF,EAGE,cAHF,EAIE,KAJF,EAIwB;AAEtB,MAAM,QAAQ,GAAG,UAAC,QAAD,EAAkC;AACjD,QAAM,KAAK,GAAG,KAAK,CAAC,aAAN,CAAiC,QAAjC,EAA2C,cAA3C,CAAd;AACA,WAAO,OAAO,KAAP,KAAiB,QAAjB,IAA6B,KAApC;AACD,GAHD;;AAKA,MAAM,QAAQ,GAAG,QAAQ,CAAC,WAAD,CAAzB;AACA,MAAI,CAAC,QAAL,EAAe;AAEf,MAAM,QAAQ,GAAG,QAAQ,CAAC,WAAD,CAAzB;AACA,MAAI,CAAC,QAAL,EAAe,OAXO,CAatB;AACA;;AACA,MAAI,WAAW,CAAC,QAAD,CAAf,EAA2B,OAfL,CAiBtB;AACA;;AACA,MAAI,KAAK,CAAC,QAAD,EAAW,QAAX,CAAT,EAA+B,OAnBT,CAqBtB;AACA;AACA;;AACA,MACE,MAAM,CAAC,IAAP,CAAY,QAAZ,EAAsB,KAAtB,CACE,UAAC,GAAD,EAAI;AAAK,WAAA,KAAK,CAAC,aAAN,CAAoB,QAApB,EAA8B,GAA9B,MAAuC,KAAvC,CAAA;AAA6C,GADxD,CADF,EAIE;AACA;AACD;;AAED,MAAM,UAAU,GACd,KAAK,CAAC,aAAN,CAA4B,WAA5B,EAAyC,YAAzC,KACA,KAAK,CAAC,aAAN,CAA4B,WAA5B,EAAyC,YAAzC,CAFF;AAGA,MAAM,SAAS,GAAG,sBAAsB,CAAC,cAAD,CAAxC;AACA,MAAM,WAAW,GAAG,GAAA,MAAA,CAAG,UAAH,EAAa,GAAb,EAAa,MAAb,CAAiB,SAAjB,CAApB,CApCsB,CAqCtB;;AACA,MAAI,QAAQ,CAAC,GAAT,CAAa,WAAb,CAAJ,EAA+B;AAC/B,EAAA,QAAQ,CAAC,GAAT,CAAa,WAAb;AAEA,MAAM,cAAc,GAAa,EAAjC,CAzCsB,CA0CtB;AACA;;AACA,MAAI,CAAC,OAAO,CAAC,QAAD,CAAR,IAAsB,CAAC,OAAO,CAAC,QAAD,CAAlC,EAA8C;AAC5C,KAAC,QAAD,EAAW,QAAX,EAAqB,OAArB,CAA6B,UAAC,KAAD,EAAM;AACjC,UAAM,QAAQ,GAAG,KAAK,CAAC,aAAN,CAAoB,KAApB,EAA2B,YAA3B,CAAjB;;AACA,UAAI,OAAO,QAAP,KAAoB,QAApB,IAAgC,CAAC,cAAc,CAAC,QAAf,CAAwB,QAAxB,CAArC,EAAwE;AACtE,QAAA,cAAc,CAAC,IAAf,CAAoB,QAApB;AACD;AACF,KALD;AAMD;;AAED,EAAA,UAAU,CAAA,OAAV,KACE,KADF,IACE,SAAA,CAAA,IAAA,CAAA,EAAA,EAAA,SAAA,EAAA,UAAA,EAAA,cAAA,CAAA,MAAA,GAiBE,uCACE,cAAc,CAAC,IAAf,CAAoB,OAApB,CADF,GAEE,6CAnBJ,GAoBE,EApBF,EAqBA,WArBA,EAsBA,QAtBA,EAuBA,QAvBA,CADF;AA0BD","sourcesContent":["import { invariant, newInvariantError } from \"../../utilities/globals/index.js\";\nimport { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\nimport type { SelectionSetNode, FieldNode } from \"graphql\";\nimport { Kind } from \"graphql\";\n\nimport type {\n  FragmentMap,\n  FragmentMapFunction,\n  StoreValue,\n  StoreObject,\n  Reference,\n} from \"../../utilities/index.js\";\nimport {\n  getFragmentFromSelection,\n  getDefaultValues,\n  getOperationDefinition,\n  getTypenameFromResult,\n  makeReference,\n  isField,\n  resultKeyNameFromField,\n  isReference,\n  shouldInclude,\n  cloneDeep,\n  addTypenameToDocument,\n  isNonEmptyArray,\n  argumentsObjectFromField,\n} from \"../../utilities/index.js\";\n\nimport type {\n  NormalizedCache,\n  ReadMergeModifyContext,\n  MergeTree,\n  InMemoryCacheConfig,\n} from \"./types.js\";\nimport {\n  isArray,\n  makeProcessedFieldsMerger,\n  fieldNameFromStoreName,\n  storeValueIsStoreObject,\n  extractFragmentContext,\n} from \"./helpers.js\";\nimport type { StoreReader } from \"./readFromStore.js\";\nimport type { InMemoryCache } from \"./inMemoryCache.js\";\nimport type { EntityStore } from \"./entityStore.js\";\nimport type { Cache } from \"../../core/index.js\";\nimport { canonicalStringify } from \"./object-canon.js\";\nimport { normalizeReadFieldOptions } from \"./policies.js\";\nimport type { ReadFieldFunction } from \"../core/types/common.js\";\n\nexport interface WriteContext extends ReadMergeModifyContext {\n  readonly written: {\n    [dataId: string]: SelectionSetNode[];\n  };\n  readonly fragmentMap: FragmentMap;\n  lookupFragment: FragmentMapFunction;\n  // General-purpose deep-merge function for use during writes.\n  merge<T>(existing: T, incoming: T): T;\n  // If true, merge functions will be called with undefined existing data.\n  overwrite: boolean;\n  incomingById: Map<\n    string,\n    {\n      storeObject: StoreObject;\n      mergeTree?: MergeTree;\n      fieldNodeSet: Set<FieldNode>;\n    }\n  >;\n  // Directive metadata for @client and @defer. We could use a bitfield for this\n  // information to save some space, and use that bitfield number as the keys in\n  // the context.flavors Map.\n  clientOnly: boolean;\n  deferred: boolean;\n  flavors: Map<string, FlavorableWriteContext>;\n}\n\ntype FlavorableWriteContext = Pick<\n  WriteContext,\n  \"clientOnly\" | \"deferred\" | \"flavors\"\n>;\n\n// Since there are only four possible combinations of context.clientOnly and\n// context.deferred values, we should need at most four \"flavors\" of any given\n// WriteContext. To avoid creating multiple copies of the same context, we cache\n// the contexts in the context.flavors Map (shared by all flavors) according to\n// their clientOnly and deferred values (always in that order).\nfunction getContextFlavor<TContext extends FlavorableWriteContext>(\n  context: TContext,\n  clientOnly: TContext[\"clientOnly\"],\n  deferred: TContext[\"deferred\"]\n): TContext {\n  const key = `${clientOnly}${deferred}`;\n  let flavored = context.flavors.get(key);\n  if (!flavored) {\n    context.flavors.set(\n      key,\n      (flavored =\n        context.clientOnly === clientOnly && context.deferred === deferred ?\n          context\n        : {\n            ...context,\n            clientOnly,\n            deferred,\n          })\n    );\n  }\n  return flavored as TContext;\n}\n\ninterface ProcessSelectionSetOptions {\n  dataId?: string;\n  result: Record<string, any>;\n  selectionSet: SelectionSetNode;\n  context: WriteContext;\n  mergeTree: MergeTree;\n}\n\nexport class StoreWriter {\n  constructor(\n    public readonly cache: InMemoryCache,\n    private reader?: StoreReader,\n    private fragments?: InMemoryCacheConfig[\"fragments\"]\n  ) {}\n\n  public writeToStore(\n    store: NormalizedCache,\n    { query, result, dataId, variables, overwrite }: Cache.WriteOptions\n  ): Reference | undefined {\n    const operationDefinition = getOperationDefinition(query)!;\n    const merger = makeProcessedFieldsMerger();\n\n    variables = {\n      ...getDefaultValues(operationDefinition),\n      ...variables!,\n    };\n\n    const context: WriteContext = {\n      store,\n      written: Object.create(null),\n      merge<T>(existing: T, incoming: T) {\n        return merger.merge(existing, incoming) as T;\n      },\n      variables,\n      varString: canonicalStringify(variables),\n      ...extractFragmentContext(query, this.fragments),\n      overwrite: !!overwrite,\n      incomingById: new Map(),\n      clientOnly: false,\n      deferred: false,\n      flavors: new Map(),\n    };\n\n    const ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: { map: new Map() },\n      context,\n    });\n\n    if (!isReference(ref)) {\n      throw newInvariantError(`Could not identify object %s`, result);\n    }\n\n    // So far, the store has not been modified, so now it's time to process\n    // context.incomingById and merge those incoming fields into context.store.\n    context.incomingById.forEach(\n      ({ storeObject, mergeTree, fieldNodeSet }, dataId) => {\n        const entityRef = makeReference(dataId);\n\n        if (mergeTree && mergeTree.map.size) {\n          const applied = this.applyMerges(\n            mergeTree,\n            entityRef,\n            storeObject,\n            context\n          );\n          if (isReference(applied)) {\n            // Assume References returned by applyMerges have already been merged\n            // into the store. See makeMergeObjectsFunction in policies.ts for an\n            // example of how this can happen.\n            return;\n          }\n          // Otherwise, applyMerges returned a StoreObject, whose fields we should\n          // merge into the store (see store.merge statement below).\n          storeObject = applied;\n        }\n\n        if (__DEV__ && !context.overwrite) {\n          const fieldsWithSelectionSets: Record<string, true> =\n            Object.create(null);\n          fieldNodeSet.forEach((field) => {\n            if (field.selectionSet) {\n              fieldsWithSelectionSets[field.name.value] = true;\n            }\n          });\n\n          const hasSelectionSet = (storeFieldName: string) =>\n            fieldsWithSelectionSets[fieldNameFromStoreName(storeFieldName)] ===\n            true;\n\n          const hasMergeFunction = (storeFieldName: string) => {\n            const childTree = mergeTree && mergeTree.map.get(storeFieldName);\n            return Boolean(childTree && childTree.info && childTree.info.merge);\n          };\n\n          Object.keys(storeObject).forEach((storeFieldName) => {\n            // If a merge function was defined for this field, trust that it\n            // did the right thing about (not) clobbering data. If the field\n            // has no selection set, it's a scalar field, so it doesn't need\n            // a merge function (even if it's an object, like JSON data).\n            if (\n              hasSelectionSet(storeFieldName) &&\n              !hasMergeFunction(storeFieldName)\n            ) {\n              warnAboutDataLoss(\n                entityRef,\n                storeObject,\n                storeFieldName,\n                context.store\n              );\n            }\n          });\n        }\n\n        store.merge(dataId, storeObject);\n      }\n    );\n\n    // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n    store.retain(ref.__ref);\n\n    return ref;\n  }\n\n  private processSelectionSet({\n    dataId,\n    result,\n    selectionSet,\n    context,\n    // This object allows processSelectionSet to report useful information\n    // to its callers without explicitly returning that information.\n    mergeTree,\n  }: ProcessSelectionSetOptions): StoreObject | Reference {\n    const { policies } = this.cache;\n\n    // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n    let incoming: StoreObject = Object.create(null);\n\n    // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n    const typename: string | undefined =\n      (dataId && policies.rootTypenamesById[dataId]) ||\n      getTypenameFromResult(result, selectionSet, context.fragmentMap) ||\n      (dataId && (context.store.get(dataId, \"__typename\") as string));\n\n    if (\"string\" === typeof typename) {\n      incoming.__typename = typename;\n    }\n\n    // This readField function will be passed as context.readField in the\n    // KeyFieldsContext object created within policies.identify (called below).\n    // In addition to reading from the existing context.store (thanks to the\n    // policies.readField(options, context) line at the very bottom), this\n    // version of readField can read from Reference objects that are currently\n    // pending in context.incomingById, which is important whenever keyFields\n    // need to be extracted from a child object that processSelectionSet has\n    // turned into a Reference.\n    const readField: ReadFieldFunction = function (this: void) {\n      const options = normalizeReadFieldOptions(\n        arguments,\n        incoming,\n        context.variables\n      );\n\n      if (isReference(options.from)) {\n        const info = context.incomingById.get(options.from.__ref);\n        if (info) {\n          const result = policies.readField(\n            {\n              ...options,\n              from: info.storeObject,\n            },\n            context\n          );\n\n          if (result !== void 0) {\n            return result;\n          }\n        }\n      }\n\n      return policies.readField(options, context);\n    };\n\n    const fieldNodeSet = new Set<FieldNode>();\n\n    this.flattenFields(\n      selectionSet,\n      result,\n      // This WriteContext will be the default context value for fields returned\n      // by the flattenFields method, but some fields may be assigned a modified\n      // context, depending on the presence of @client and other directives.\n      context,\n      typename\n    ).forEach((context, field) => {\n      const resultFieldKey = resultKeyNameFromField(field);\n      const value = result[resultFieldKey];\n\n      fieldNodeSet.add(field);\n\n      if (value !== void 0) {\n        const storeFieldName = policies.getStoreFieldName({\n          typename,\n          fieldName: field.name.value,\n          field,\n          variables: context.variables,\n        });\n\n        const childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n        let incomingValue = this.processFieldValue(\n          value,\n          field,\n          // Reset context.clientOnly and context.deferred to their default\n          // values before processing nested selection sets.\n          field.selectionSet ?\n            getContextFlavor(context, false, false)\n          : context,\n          childTree\n        );\n\n        // To determine if this field holds a child object with a merge function\n        // defined in its type policy (see PR #7070), we need to figure out the\n        // child object's __typename.\n        let childTypename: string | undefined;\n\n        // The field's value can be an object that has a __typename only if the\n        // field has a selection set. Otherwise incomingValue is scalar.\n        if (\n          field.selectionSet &&\n          (isReference(incomingValue) || storeValueIsStoreObject(incomingValue))\n        ) {\n          childTypename = readField<string>(\"__typename\", incomingValue);\n        }\n\n        const merge = policies.getMergeFunction(\n          typename,\n          field.name.value,\n          childTypename\n        );\n\n        if (merge) {\n          childTree.info = {\n            // TODO Check compatibility against any existing childTree.field?\n            field,\n            typename,\n            merge,\n          };\n        } else {\n          maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n        }\n\n        incoming = context.merge(incoming, {\n          [storeFieldName]: incomingValue,\n        });\n      } else if (\n        __DEV__ &&\n        !context.clientOnly &&\n        !context.deferred &&\n        !addTypenameToDocument.added(field) &&\n        // If the field has a read function, it may be a synthetic field or\n        // provide a default value, so its absence from the written data should\n        // not be cause for alarm.\n        !policies.getReadFunction(typename, field.name.value)\n      ) {\n        invariant.error(\n          `Missing field '%s' while writing result %o`,\n          resultKeyNameFromField(field),\n          result\n        );\n      }\n    });\n\n    // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n    try {\n      const [id, keyObject] = policies.identify(result, {\n        typename,\n        selectionSet,\n        fragmentMap: context.fragmentMap,\n        storeObject: incoming,\n        readField,\n      });\n\n      // If dataId was not provided, fall back to the id just generated by\n      // policies.identify.\n      dataId = dataId || id;\n\n      // Write any key fields that were used during identification, even if\n      // they were not mentioned in the original query.\n      if (keyObject) {\n        // TODO Reverse the order of the arguments?\n        incoming = context.merge(incoming, keyObject);\n      }\n    } catch (e) {\n      // If dataId was provided, tolerate failure of policies.identify.\n      if (!dataId) throw e;\n    }\n\n    if (\"string\" === typeof dataId) {\n      const dataRef = makeReference(dataId);\n\n      // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n      const sets = context.written[dataId] || (context.written[dataId] = []);\n      if (sets.indexOf(selectionSet) >= 0) return dataRef;\n      sets.push(selectionSet);\n\n      // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n      if (\n        this.reader &&\n        this.reader.isFresh(result, dataRef, selectionSet, context)\n      ) {\n        return dataRef;\n      }\n\n      const previous = context.incomingById.get(dataId);\n      if (previous) {\n        previous.storeObject = context.merge(previous.storeObject, incoming);\n        previous.mergeTree = mergeMergeTrees(previous.mergeTree, mergeTree);\n        fieldNodeSet.forEach((field) => previous.fieldNodeSet.add(field));\n      } else {\n        context.incomingById.set(dataId, {\n          storeObject: incoming,\n          // Save a reference to mergeTree only if it is not empty, because\n          // empty MergeTrees may be recycled by maybeRecycleChildMergeTree and\n          // reused for entirely different parts of the result tree.\n          mergeTree: mergeTreeIsEmpty(mergeTree) ? void 0 : mergeTree,\n          fieldNodeSet,\n        });\n      }\n\n      return dataRef;\n    }\n\n    return incoming;\n  }\n\n  private processFieldValue(\n    value: any,\n    field: FieldNode,\n    context: WriteContext,\n    mergeTree: MergeTree\n  ): StoreValue {\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return __DEV__ ? cloneDeep(value) : value;\n    }\n\n    if (isArray(value)) {\n      return value.map((item, i) => {\n        const value = this.processFieldValue(\n          item,\n          field,\n          context,\n          getChildMergeTree(mergeTree, i)\n        );\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context,\n      mergeTree,\n    });\n  }\n\n  // Implements https://spec.graphql.org/draft/#sec-Field-Collection, but with\n  // some additions for tracking @client and @defer directives.\n  private flattenFields<\n    TContext extends Pick<\n      WriteContext,\n      | \"clientOnly\"\n      | \"deferred\"\n      | \"flavors\"\n      | \"fragmentMap\"\n      | \"lookupFragment\"\n      | \"variables\"\n    >,\n  >(\n    selectionSet: SelectionSetNode,\n    result: Record<string, any>,\n    context: TContext,\n    typename = getTypenameFromResult(result, selectionSet, context.fragmentMap)\n  ): Map<FieldNode, TContext> {\n    const fieldMap = new Map<FieldNode, TContext>();\n    const { policies } = this.cache;\n\n    const limitingTrie = new Trie<{\n      // Tracks whether (selectionSet, clientOnly, deferred) has been flattened\n      // before. The GraphQL specification only uses the fragment name for\n      // skipping previously visited fragments, but the top-level fragment\n      // selection set corresponds 1:1 with the fagment name (and is slightly\n      // easier too work with), and we need to consider clientOnly and deferred\n      // values as well, potentially revisiting selection sets that were\n      // previously visited with different inherited configurations of those\n      // directives.\n      visited?: boolean;\n    }>(false); // No need for WeakMap, since limitingTrie does not escape.\n\n    (function flatten(\n      this: void,\n      selectionSet: SelectionSetNode,\n      inheritedContext: TContext\n    ) {\n      const visitedNode = limitingTrie.lookup(\n        selectionSet,\n        // Because we take inheritedClientOnly and inheritedDeferred into\n        // consideration here (in addition to selectionSet), it's possible for\n        // the same selection set to be flattened more than once, if it appears\n        // in the query with different @client and/or @directive configurations.\n        inheritedContext.clientOnly,\n        inheritedContext.deferred\n      );\n      if (visitedNode.visited) return;\n      visitedNode.visited = true;\n\n      selectionSet.selections.forEach((selection) => {\n        if (!shouldInclude(selection, context.variables)) return;\n\n        let { clientOnly, deferred } = inheritedContext;\n        if (\n          // Since the presence of @client or @defer on this field can only\n          // cause clientOnly or deferred to become true, we can skip the\n          // forEach loop if both clientOnly and deferred are already true.\n          !(clientOnly && deferred) &&\n          isNonEmptyArray(selection.directives)\n        ) {\n          selection.directives.forEach((dir) => {\n            const name = dir.name.value;\n            if (name === \"client\") clientOnly = true;\n            if (name === \"defer\") {\n              const args = argumentsObjectFromField(dir, context.variables);\n              // The @defer directive takes an optional args.if boolean\n              // argument, similar to @include(if: boolean). Note that\n              // @defer(if: false) does not make context.deferred false, but\n              // instead behaves as if there was no @defer directive.\n              if (!args || (args as { if?: boolean }).if !== false) {\n                deferred = true;\n              }\n              // TODO In the future, we may want to record args.label using\n              // context.deferred, if a label is specified.\n            }\n          });\n        }\n\n        if (isField(selection)) {\n          const existing = fieldMap.get(selection);\n          if (existing) {\n            // If this field has been visited along another recursive path\n            // before, the final context should have clientOnly or deferred set\n            // to true only if *all* paths have the directive (hence the &&).\n            clientOnly = clientOnly && existing.clientOnly;\n            deferred = deferred && existing.deferred;\n          }\n\n          fieldMap.set(\n            selection,\n            getContextFlavor(context, clientOnly, deferred)\n          );\n        } else {\n          const fragment = getFragmentFromSelection(\n            selection,\n            context.lookupFragment\n          );\n\n          if (!fragment && selection.kind === Kind.FRAGMENT_SPREAD) {\n            throw newInvariantError(\n              `No fragment named %s`,\n              selection.name.value\n            );\n          }\n\n          if (\n            fragment &&\n            policies.fragmentMatches(\n              fragment,\n              typename,\n              result,\n              context.variables\n            )\n          ) {\n            flatten(\n              fragment.selectionSet,\n              getContextFlavor(context, clientOnly, deferred)\n            );\n          }\n        }\n      });\n    })(selectionSet, context);\n\n    return fieldMap;\n  }\n\n  private applyMerges<T extends StoreValue>(\n    mergeTree: MergeTree,\n    existing: StoreValue,\n    incoming: T,\n    context: WriteContext,\n    getStorageArgs?: Parameters<EntityStore[\"getStorage\"]>\n  ): T | Reference {\n    if (mergeTree.map.size && !isReference(incoming)) {\n      const e: StoreObject | Reference | undefined =\n        // Items in the same position in different arrays are not\n        // necessarily related to each other, so when incoming is an array\n        // we process its elements as if there was no existing data.\n        (\n          !isArray(incoming) &&\n          // Likewise, existing must be either a Reference or a StoreObject\n          // in order for its fields to be safe to merge with the fields of\n          // the incoming object.\n          (isReference(existing) || storeValueIsStoreObject(existing))\n        ) ?\n          existing\n        : void 0;\n\n      // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n      const i = incoming as StoreObject | StoreValue[];\n\n      // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n      if (e && !getStorageArgs) {\n        getStorageArgs = [isReference(e) ? e.__ref : e];\n      }\n\n      // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n      let changedFields: Map<string | number, StoreValue> | undefined;\n\n      const getValue = (\n        from: typeof e | typeof i,\n        name: string | number\n      ): StoreValue => {\n        return (\n          isArray(from) ?\n            typeof name === \"number\" ?\n              from[name]\n            : void 0\n          : context.store.getFieldValue(from, String(name))\n        );\n      };\n\n      mergeTree.map.forEach((childTree, storeFieldName) => {\n        const eVal = getValue(e, storeFieldName);\n        const iVal = getValue(i, storeFieldName);\n        // If we have no incoming data, leave any existing data untouched.\n        if (void 0 === iVal) return;\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        const aVal = this.applyMerges(\n          childTree,\n          eVal,\n          iVal,\n          context,\n          getStorageArgs\n        );\n        if (aVal !== iVal) {\n          changedFields = changedFields || new Map();\n          changedFields.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = (isArray(i) ? i.slice(0) : { ...i }) as T;\n        changedFields.forEach((value, name) => {\n          (incoming as any)[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(\n        existing,\n        incoming,\n        mergeTree.info,\n        context,\n        getStorageArgs && context.store.getStorage(...getStorageArgs)\n      );\n    }\n\n    return incoming;\n  }\n}\n\nconst emptyMergeTreePool: MergeTree[] = [];\n\nfunction getChildMergeTree(\n  { map }: MergeTree,\n  name: string | number\n): MergeTree {\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || { map: new Map() });\n  }\n  return map.get(name)!;\n}\n\nfunction mergeMergeTrees(\n  left: MergeTree | undefined,\n  right: MergeTree | undefined\n): MergeTree {\n  if (left === right || !right || mergeTreeIsEmpty(right)) return left!;\n  if (!left || mergeTreeIsEmpty(left)) return right;\n\n  const info =\n    left.info && right.info ?\n      {\n        ...left.info,\n        ...right.info,\n      }\n    : left.info || right.info;\n\n  const needToMergeMaps = left.map.size && right.map.size;\n  const map =\n    needToMergeMaps ? new Map()\n    : left.map.size ? left.map\n    : right.map;\n\n  const merged = { info, map };\n\n  if (needToMergeMaps) {\n    const remainingRightKeys = new Set(right.map.keys());\n\n    left.map.forEach((leftTree, key) => {\n      merged.map.set(key, mergeMergeTrees(leftTree, right.map.get(key)));\n      remainingRightKeys.delete(key);\n    });\n\n    remainingRightKeys.forEach((key) => {\n      merged.map.set(\n        key,\n        mergeMergeTrees(right.map.get(key), left.map.get(key))\n      );\n    });\n  }\n\n  return merged;\n}\n\nfunction mergeTreeIsEmpty(tree: MergeTree | undefined): boolean {\n  return !tree || !(tree.info || tree.map.size);\n}\n\nfunction maybeRecycleChildMergeTree({ map }: MergeTree, name: string | number) {\n  const childTree = map.get(name);\n  if (childTree && mergeTreeIsEmpty(childTree)) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nconst warnings = new Set<string>();\n\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(\n  existingRef: Reference,\n  incomingObj: StoreObject,\n  storeFieldName: string,\n  store: NormalizedCache\n) {\n  const getChild = (objOrRef: StoreObject | Reference): StoreObject | false => {\n    const child = store.getFieldValue<StoreObject>(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  const existing = getChild(existingRef);\n  if (!existing) return;\n\n  const incoming = getChild(incomingObj);\n  if (!incoming) return;\n\n  // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n  if (isReference(existing)) return;\n\n  // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n  if (equal(existing, incoming)) return;\n\n  // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n  if (\n    Object.keys(existing).every(\n      (key) => store.getFieldValue(incoming, key) !== void 0\n    )\n  ) {\n    return;\n  }\n\n  const parentType =\n    store.getFieldValue<string>(existingRef, \"__typename\") ||\n    store.getFieldValue<string>(incomingObj, \"__typename\");\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const typeDotName = `${parentType}.${fieldName}`;\n  // Avoid warning more than once for the same type and field name.\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n\n  const childTypenames: string[] = [];\n  // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n  if (!isArray(existing) && !isArray(incoming)) {\n    [existing, incoming].forEach((child) => {\n      const typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" && !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  invariant.warn(\n    `Cache data may be lost when replacing the %s field of a %s object.\n\nThis could cause additional (usually avoidable) network requests to fetch data that were otherwise cached.\n\nTo address this problem (which is not a bug in Apollo Client), %sdefine a custom merge function for the %s field, so InMemoryCache can safely merge these objects:\n\n  existing: %s\n  incoming: %s\n\nFor more information about these options, please refer to the documentation:\n\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\n`,\n    fieldName,\n    parentType,\n    childTypenames.length ?\n      \"either ensure all objects of type \" +\n        childTypenames.join(\" and \") +\n        \" have an ID or a custom merge function, or \"\n    : \"\",\n    typeDotName,\n    existing,\n    incoming\n  );\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}