{"ast":null,"code":"import { __assign, __extends, __rest } from \"tslib\";\nimport { invariant } from \"../../utilities/globals/index.js\";\nimport { dep } from \"optimism\";\nimport { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\nimport { isReference, makeReference, DeepMerger, maybeDeepFreeze, canUseWeakMap, isNonNullObject } from \"../../utilities/index.js\";\nimport { hasOwn, fieldNameFromStoreName } from \"./helpers.js\";\nvar DELETE = Object.create(null);\n\nvar delModifier = function () {\n  return DELETE;\n};\n\nvar INVALIDATE = Object.create(null);\n\nvar EntityStore =\n/** @class */\nfunction () {\n  function EntityStore(policies, group) {\n    var _this = this;\n\n    this.policies = policies;\n    this.group = group;\n    this.data = Object.create(null); // Maps root entity IDs to the number of times they have been retained, minus\n    // the number of times they have been released. Retained entities keep other\n    // entities they reference (even indirectly) from being garbage collected.\n\n    this.rootIds = Object.create(null); // Lazily tracks { __ref: <dataId> } strings contained by this.data[dataId].\n\n    this.refs = Object.create(null); // Bound function that can be passed around to provide easy access to fields\n    // of Reference objects as well as ordinary objects.\n\n    this.getFieldValue = function (objectOrReference, storeFieldName) {\n      return maybeDeepFreeze(isReference(objectOrReference) ? _this.get(objectOrReference.__ref, storeFieldName) : objectOrReference && objectOrReference[storeFieldName]);\n    }; // Returns true for non-normalized StoreObjects and non-dangling\n    // References, indicating that readField(name, objOrRef) has a chance of\n    // working. Useful for filtering out dangling references from lists.\n\n\n    this.canRead = function (objOrRef) {\n      return isReference(objOrRef) ? _this.has(objOrRef.__ref) : typeof objOrRef === \"object\";\n    }; // Bound function that converts an id or an object with a __typename and\n    // primary key fields to a Reference object. If called with a Reference object,\n    // that same Reference object is returned. Pass true for mergeIntoStore to persist\n    // an object into the store.\n\n\n    this.toReference = function (objOrIdOrRef, mergeIntoStore) {\n      if (typeof objOrIdOrRef === \"string\") {\n        return makeReference(objOrIdOrRef);\n      }\n\n      if (isReference(objOrIdOrRef)) {\n        return objOrIdOrRef;\n      }\n\n      var id = _this.policies.identify(objOrIdOrRef)[0];\n\n      if (id) {\n        var ref = makeReference(id);\n\n        if (mergeIntoStore) {\n          _this.merge(id, objOrIdOrRef);\n        }\n\n        return ref;\n      }\n    };\n  } // Although the EntityStore class is abstract, it contains concrete\n  // implementations of the various NormalizedCache interface methods that\n  // are inherited by the Root and Layer subclasses.\n\n\n  EntityStore.prototype.toObject = function () {\n    return __assign({}, this.data);\n  };\n\n  EntityStore.prototype.has = function (dataId) {\n    return this.lookup(dataId, true) !== void 0;\n  };\n\n  EntityStore.prototype.get = function (dataId, fieldName) {\n    this.group.depend(dataId, fieldName);\n\n    if (hasOwn.call(this.data, dataId)) {\n      var storeObject = this.data[dataId];\n\n      if (storeObject && hasOwn.call(storeObject, fieldName)) {\n        return storeObject[fieldName];\n      }\n    }\n\n    if (fieldName === \"__typename\" && hasOwn.call(this.policies.rootTypenamesById, dataId)) {\n      return this.policies.rootTypenamesById[dataId];\n    }\n\n    if (this instanceof Layer) {\n      return this.parent.get(dataId, fieldName);\n    }\n  };\n\n  EntityStore.prototype.lookup = function (dataId, dependOnExistence) {\n    // The has method (above) calls lookup with dependOnExistence = true, so\n    // that it can later be invalidated when we add or remove a StoreObject for\n    // this dataId. Any consumer who cares about the contents of the StoreObject\n    // should not rely on this dependency, since the contents could change\n    // without the object being added or removed.\n    if (dependOnExistence) this.group.depend(dataId, \"__exists\");\n\n    if (hasOwn.call(this.data, dataId)) {\n      return this.data[dataId];\n    }\n\n    if (this instanceof Layer) {\n      return this.parent.lookup(dataId, dependOnExistence);\n    }\n\n    if (this.policies.rootTypenamesById[dataId]) {\n      return Object.create(null);\n    }\n  };\n\n  EntityStore.prototype.merge = function (older, newer) {\n    var _this = this;\n\n    var dataId; // Convert unexpected references to ID strings.\n\n    if (isReference(older)) older = older.__ref;\n    if (isReference(newer)) newer = newer.__ref;\n    var existing = typeof older === \"string\" ? this.lookup(dataId = older) : older;\n    var incoming = typeof newer === \"string\" ? this.lookup(dataId = newer) : newer; // If newer was a string ID, but that ID was not defined in this store,\n    // then there are no fields to be merged, so we're done.\n\n    if (!incoming) return;\n    invariant(typeof dataId === \"string\", 1);\n    var merged = new DeepMerger(storeObjectReconciler).merge(existing, incoming); // Even if merged === existing, existing may have come from a lower\n    // layer, so we always need to set this.data[dataId] on this level.\n\n    this.data[dataId] = merged;\n\n    if (merged !== existing) {\n      delete this.refs[dataId];\n\n      if (this.group.caching) {\n        var fieldsToDirty_1 = Object.create(null); // If we added a new StoreObject where there was previously none, dirty\n        // anything that depended on the existence of this dataId, such as the\n        // EntityStore#has method.\n\n        if (!existing) fieldsToDirty_1.__exists = 1; // Now invalidate dependents who called getFieldValue for any fields\n        // that are changing as a result of this merge.\n\n        Object.keys(incoming).forEach(function (storeFieldName) {\n          if (!existing || existing[storeFieldName] !== merged[storeFieldName]) {\n            // Always dirty the full storeFieldName, which may include\n            // serialized arguments following the fieldName prefix.\n            fieldsToDirty_1[storeFieldName] = 1; // Also dirty fieldNameFromStoreName(storeFieldName) if it's\n            // different from storeFieldName and this field does not have\n            // keyArgs configured, because that means the cache can't make\n            // any assumptions about how field values with the same field\n            // name but different arguments might be interrelated, so it\n            // must err on the side of invalidating all field values that\n            // share the same short fieldName, regardless of arguments.\n\n            var fieldName = fieldNameFromStoreName(storeFieldName);\n\n            if (fieldName !== storeFieldName && !_this.policies.hasKeyArgs(merged.__typename, fieldName)) {\n              fieldsToDirty_1[fieldName] = 1;\n            } // If merged[storeFieldName] has become undefined, and this is the\n            // Root layer, actually delete the property from the merged object,\n            // which is guaranteed to have been created fresh in this method.\n\n\n            if (merged[storeFieldName] === void 0 && !(_this instanceof Layer)) {\n              delete merged[storeFieldName];\n            }\n          }\n        });\n\n        if (fieldsToDirty_1.__typename && !(existing && existing.__typename) && // Since we return default root __typename strings\n        // automatically from store.get, we don't need to dirty the\n        // ROOT_QUERY.__typename field if merged.__typename is equal\n        // to the default string (usually \"Query\").\n        this.policies.rootTypenamesById[dataId] === merged.__typename) {\n          delete fieldsToDirty_1.__typename;\n        }\n\n        Object.keys(fieldsToDirty_1).forEach(function (fieldName) {\n          return _this.group.dirty(dataId, fieldName);\n        });\n      }\n    }\n  };\n\n  EntityStore.prototype.modify = function (dataId, fields) {\n    var _this = this;\n\n    var storeObject = this.lookup(dataId);\n\n    if (storeObject) {\n      var changedFields_1 = Object.create(null);\n      var needToMerge_1 = false;\n      var allDeleted_1 = true;\n      var sharedDetails_1 = {\n        DELETE: DELETE,\n        INVALIDATE: INVALIDATE,\n        isReference: isReference,\n        toReference: this.toReference,\n        canRead: this.canRead,\n        readField: function (fieldNameOrOptions, from) {\n          return _this.policies.readField(typeof fieldNameOrOptions === \"string\" ? {\n            fieldName: fieldNameOrOptions,\n            from: from || makeReference(dataId)\n          } : fieldNameOrOptions, {\n            store: _this\n          });\n        }\n      };\n      Object.keys(storeObject).forEach(function (storeFieldName) {\n        var fieldName = fieldNameFromStoreName(storeFieldName);\n        var fieldValue = storeObject[storeFieldName];\n        if (fieldValue === void 0) return;\n        var modify = typeof fields === \"function\" ? fields : fields[storeFieldName] || fields[fieldName];\n\n        if (modify) {\n          var newValue = modify === delModifier ? DELETE : modify(maybeDeepFreeze(fieldValue), __assign(__assign({}, sharedDetails_1), {\n            fieldName: fieldName,\n            storeFieldName: storeFieldName,\n            storage: _this.getStorage(dataId, storeFieldName)\n          }));\n\n          if (newValue === INVALIDATE) {\n            _this.group.dirty(dataId, storeFieldName);\n          } else {\n            if (newValue === DELETE) newValue = void 0;\n\n            if (newValue !== fieldValue) {\n              changedFields_1[storeFieldName] = newValue;\n              needToMerge_1 = true;\n              fieldValue = newValue;\n\n              if (globalThis.__DEV__ !== false) {\n                var checkReference = function (ref) {\n                  if (_this.lookup(ref.__ref) === undefined) {\n                    globalThis.__DEV__ !== false && invariant.warn(2, ref);\n                    return true;\n                  }\n                };\n\n                if (isReference(newValue)) {\n                  checkReference(newValue);\n                } else if (Array.isArray(newValue)) {\n                  // Warn about writing \"mixed\" arrays of Reference and non-Reference objects\n                  var seenReference = false;\n                  var someNonReference = void 0;\n\n                  for (var _i = 0, newValue_1 = newValue; _i < newValue_1.length; _i++) {\n                    var value = newValue_1[_i];\n\n                    if (isReference(value)) {\n                      seenReference = true;\n                      if (checkReference(value)) break;\n                    } else {\n                      // Do not warn on primitive values, since those could never be represented\n                      // by a reference. This is a valid (albeit uncommon) use case.\n                      if (typeof value === \"object\" && !!value) {\n                        var id = _this.policies.identify(value)[0]; // check if object could even be referenced, otherwise we are not interested in it for this warning\n\n\n                        if (id) {\n                          someNonReference = value;\n                        }\n                      }\n                    }\n\n                    if (seenReference && someNonReference !== undefined) {\n                      globalThis.__DEV__ !== false && invariant.warn(3, someNonReference);\n                      break;\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n\n        if (fieldValue !== void 0) {\n          allDeleted_1 = false;\n        }\n      });\n\n      if (needToMerge_1) {\n        this.merge(dataId, changedFields_1);\n\n        if (allDeleted_1) {\n          if (this instanceof Layer) {\n            this.data[dataId] = void 0;\n          } else {\n            delete this.data[dataId];\n          }\n\n          this.group.dirty(dataId, \"__exists\");\n        }\n\n        return true;\n      }\n    }\n\n    return false;\n  }; // If called with only one argument, removes the entire entity\n  // identified by dataId. If called with a fieldName as well, removes all\n  // fields of that entity whose names match fieldName according to the\n  // fieldNameFromStoreName helper function. If called with a fieldName\n  // and variables, removes all fields of that entity whose names match fieldName\n  // and whose arguments when cached exactly match the variables passed.\n\n\n  EntityStore.prototype.delete = function (dataId, fieldName, args) {\n    var _a;\n\n    var storeObject = this.lookup(dataId);\n\n    if (storeObject) {\n      var typename = this.getFieldValue(storeObject, \"__typename\");\n      var storeFieldName = fieldName && args ? this.policies.getStoreFieldName({\n        typename: typename,\n        fieldName: fieldName,\n        args: args\n      }) : fieldName;\n      return this.modify(dataId, storeFieldName ? (_a = {}, _a[storeFieldName] = delModifier, _a) : delModifier);\n    }\n\n    return false;\n  };\n\n  EntityStore.prototype.evict = function (options, limit) {\n    var evicted = false;\n\n    if (options.id) {\n      if (hasOwn.call(this.data, options.id)) {\n        evicted = this.delete(options.id, options.fieldName, options.args);\n      }\n\n      if (this instanceof Layer && this !== limit) {\n        evicted = this.parent.evict(options, limit) || evicted;\n      } // Always invalidate the field to trigger rereading of watched\n      // queries, even if no cache data was modified by the eviction,\n      // because queries may depend on computed fields with custom read\n      // functions, whose values are not stored in the EntityStore.\n\n\n      if (options.fieldName || evicted) {\n        this.group.dirty(options.id, options.fieldName || \"__exists\");\n      }\n    }\n\n    return evicted;\n  };\n\n  EntityStore.prototype.clear = function () {\n    this.replace(null);\n  };\n\n  EntityStore.prototype.extract = function () {\n    var _this = this;\n\n    var obj = this.toObject();\n    var extraRootIds = [];\n    this.getRootIdSet().forEach(function (id) {\n      if (!hasOwn.call(_this.policies.rootTypenamesById, id)) {\n        extraRootIds.push(id);\n      }\n    });\n\n    if (extraRootIds.length) {\n      obj.__META = {\n        extraRootIds: extraRootIds.sort()\n      };\n    }\n\n    return obj;\n  };\n\n  EntityStore.prototype.replace = function (newData) {\n    var _this = this;\n\n    Object.keys(this.data).forEach(function (dataId) {\n      if (!(newData && hasOwn.call(newData, dataId))) {\n        _this.delete(dataId);\n      }\n    });\n\n    if (newData) {\n      var __META = newData.__META,\n          rest_1 = __rest(newData, [\"__META\"]);\n\n      Object.keys(rest_1).forEach(function (dataId) {\n        _this.merge(dataId, rest_1[dataId]);\n      });\n\n      if (__META) {\n        __META.extraRootIds.forEach(this.retain, this);\n      }\n    }\n  };\n\n  EntityStore.prototype.retain = function (rootId) {\n    return this.rootIds[rootId] = (this.rootIds[rootId] || 0) + 1;\n  };\n\n  EntityStore.prototype.release = function (rootId) {\n    if (this.rootIds[rootId] > 0) {\n      var count = --this.rootIds[rootId];\n      if (!count) delete this.rootIds[rootId];\n      return count;\n    }\n\n    return 0;\n  }; // Return a Set<string> of all the ID strings that have been retained by\n  // this layer/root *and* any layers/roots beneath it.\n\n\n  EntityStore.prototype.getRootIdSet = function (ids) {\n    if (ids === void 0) {\n      ids = new Set();\n    }\n\n    Object.keys(this.rootIds).forEach(ids.add, ids);\n\n    if (this instanceof Layer) {\n      this.parent.getRootIdSet(ids);\n    } else {\n      // Official singleton IDs like ROOT_QUERY and ROOT_MUTATION are\n      // always considered roots for garbage collection, regardless of\n      // their retainment counts in this.rootIds.\n      Object.keys(this.policies.rootTypenamesById).forEach(ids.add, ids);\n    }\n\n    return ids;\n  }; // The goal of garbage collection is to remove IDs from the Root layer of the\n  // store that are no longer reachable starting from any IDs that have been\n  // explicitly retained (see retain and release, above). Returns an array of\n  // dataId strings that were removed from the store.\n\n\n  EntityStore.prototype.gc = function () {\n    var _this = this;\n\n    var ids = this.getRootIdSet();\n    var snapshot = this.toObject();\n    ids.forEach(function (id) {\n      if (hasOwn.call(snapshot, id)) {\n        // Because we are iterating over an ECMAScript Set, the IDs we add here\n        // will be visited in later iterations of the forEach loop only if they\n        // were not previously contained by the Set.\n        Object.keys(_this.findChildRefIds(id)).forEach(ids.add, ids); // By removing IDs from the snapshot object here, we protect them from\n        // getting removed from the root store layer below.\n\n        delete snapshot[id];\n      }\n    });\n    var idsToRemove = Object.keys(snapshot);\n\n    if (idsToRemove.length) {\n      var root_1 = this;\n\n      while (root_1 instanceof Layer) root_1 = root_1.parent;\n\n      idsToRemove.forEach(function (id) {\n        return root_1.delete(id);\n      });\n    }\n\n    return idsToRemove;\n  };\n\n  EntityStore.prototype.findChildRefIds = function (dataId) {\n    if (!hasOwn.call(this.refs, dataId)) {\n      var found_1 = this.refs[dataId] = Object.create(null);\n      var root = this.data[dataId];\n      if (!root) return found_1;\n      var workSet_1 = new Set([root]); // Within the store, only arrays and objects can contain child entity\n      // references, so we can prune the traversal using this predicate:\n\n      workSet_1.forEach(function (obj) {\n        if (isReference(obj)) {\n          found_1[obj.__ref] = true; // In rare cases, a { __ref } Reference object may have other fields.\n          // This often indicates a mismerging of References with StoreObjects,\n          // but garbage collection should not be fooled by a stray __ref\n          // property in a StoreObject (ignoring all the other fields just\n          // because the StoreObject looks like a Reference). To avoid this\n          // premature termination of findChildRefIds recursion, we fall through\n          // to the code below, which will handle any other properties of obj.\n        }\n\n        if (isNonNullObject(obj)) {\n          Object.keys(obj).forEach(function (key) {\n            var child = obj[key]; // No need to add primitive values to the workSet, since they cannot\n            // contain reference objects.\n\n            if (isNonNullObject(child)) {\n              workSet_1.add(child);\n            }\n          });\n        }\n      });\n    }\n\n    return this.refs[dataId];\n  };\n\n  EntityStore.prototype.makeCacheKey = function () {\n    return this.group.keyMaker.lookupArray(arguments);\n  };\n\n  return EntityStore;\n}();\n\nexport { EntityStore }; // A single CacheGroup represents a set of one or more EntityStore objects,\n// typically the Root store in a CacheGroup by itself, and all active Layer\n// stores in a group together. A single EntityStore object belongs to only\n// one CacheGroup, store.group. The CacheGroup is responsible for tracking\n// dependencies, so store.group is helpful for generating unique keys for\n// cached results that need to be invalidated when/if those dependencies\n// change. If we used the EntityStore objects themselves as cache keys (that\n// is, store rather than store.group), the cache would become unnecessarily\n// fragmented by all the different Layer objects. Instead, the CacheGroup\n// approach allows all optimistic Layer objects in the same linked list to\n// belong to one CacheGroup, with the non-optimistic Root object belonging\n// to another CacheGroup, allowing resultCaching dependencies to be tracked\n// separately for optimistic and non-optimistic entity data.\n\nvar CacheGroup =\n/** @class */\nfunction () {\n  function CacheGroup(caching, parent) {\n    if (parent === void 0) {\n      parent = null;\n    }\n\n    this.caching = caching;\n    this.parent = parent;\n    this.d = null;\n    this.resetCaching();\n  }\n\n  CacheGroup.prototype.resetCaching = function () {\n    this.d = this.caching ? dep() : null;\n    this.keyMaker = new Trie(canUseWeakMap);\n  };\n\n  CacheGroup.prototype.depend = function (dataId, storeFieldName) {\n    if (this.d) {\n      this.d(makeDepKey(dataId, storeFieldName));\n      var fieldName = fieldNameFromStoreName(storeFieldName);\n\n      if (fieldName !== storeFieldName) {\n        // Fields with arguments that contribute extra identifying\n        // information to the fieldName (thus forming the storeFieldName)\n        // depend not only on the full storeFieldName but also on the\n        // short fieldName, so the field can be invalidated using either\n        // level of specificity.\n        this.d(makeDepKey(dataId, fieldName));\n      }\n\n      if (this.parent) {\n        this.parent.depend(dataId, storeFieldName);\n      }\n    }\n  };\n\n  CacheGroup.prototype.dirty = function (dataId, storeFieldName) {\n    if (this.d) {\n      this.d.dirty(makeDepKey(dataId, storeFieldName), // When storeFieldName === \"__exists\", that means the entity identified\n      // by dataId has either disappeared from the cache or was newly added,\n      // so the result caching system would do well to \"forget everything it\n      // knows\" about that object. To achieve that kind of invalidation, we\n      // not only dirty the associated result cache entry, but also remove it\n      // completely from the dependency graph. For the optimism implementation\n      // details, see https://github.com/benjamn/optimism/pull/195.\n      storeFieldName === \"__exists\" ? \"forget\" : \"setDirty\");\n    }\n  };\n\n  return CacheGroup;\n}();\n\nfunction makeDepKey(dataId, storeFieldName) {\n  // Since field names cannot have '#' characters in them, this method\n  // of joining the field name and the ID should be unambiguous, and much\n  // cheaper than JSON.stringify([dataId, fieldName]).\n  return storeFieldName + \"#\" + dataId;\n}\n\nexport function maybeDependOnExistenceOfEntity(store, entityId) {\n  if (supportsResultCaching(store)) {\n    // We use this pseudo-field __exists elsewhere in the EntityStore code to\n    // represent changes in the existence of the entity object identified by\n    // entityId. This dependency gets reliably dirtied whenever an object with\n    // this ID is deleted (or newly created) within this group, so any result\n    // cache entries (for example, StoreReader#executeSelectionSet results) that\n    // depend on __exists for this entityId will get dirtied as well, leading to\n    // the eventual recomputation (instead of reuse) of those result objects the\n    // next time someone reads them from the cache.\n    store.group.depend(entityId, \"__exists\");\n  }\n}\n\n(function (EntityStore) {\n  // Refer to this class as EntityStore.Root outside this namespace.\n  var Root =\n  /** @class */\n  function (_super) {\n    __extends(Root, _super);\n\n    function Root(_a) {\n      var policies = _a.policies,\n          _b = _a.resultCaching,\n          resultCaching = _b === void 0 ? true : _b,\n          seed = _a.seed;\n\n      var _this = _super.call(this, policies, new CacheGroup(resultCaching)) || this;\n\n      _this.stump = new Stump(_this);\n      _this.storageTrie = new Trie(canUseWeakMap);\n      if (seed) _this.replace(seed);\n      return _this;\n    }\n\n    Root.prototype.addLayer = function (layerId, replay) {\n      // Adding an optimistic Layer on top of the Root actually adds the Layer\n      // on top of the Stump, so the Stump always comes between the Root and\n      // any Layer objects that we've added.\n      return this.stump.addLayer(layerId, replay);\n    };\n\n    Root.prototype.removeLayer = function () {\n      // Never remove the root layer.\n      return this;\n    };\n\n    Root.prototype.getStorage = function () {\n      return this.storageTrie.lookupArray(arguments);\n    };\n\n    return Root;\n  }(EntityStore);\n\n  EntityStore.Root = Root;\n})(EntityStore || (EntityStore = {})); // Not exported, since all Layer instances are created by the addLayer method\n// of the EntityStore.Root class.\n\n\nvar Layer =\n/** @class */\nfunction (_super) {\n  __extends(Layer, _super);\n\n  function Layer(id, parent, replay, group) {\n    var _this = _super.call(this, parent.policies, group) || this;\n\n    _this.id = id;\n    _this.parent = parent;\n    _this.replay = replay;\n    _this.group = group;\n    replay(_this);\n    return _this;\n  }\n\n  Layer.prototype.addLayer = function (layerId, replay) {\n    return new Layer(layerId, this, replay, this.group);\n  };\n\n  Layer.prototype.removeLayer = function (layerId) {\n    var _this = this; // Remove all instances of the given id, not just the first one.\n\n\n    var parent = this.parent.removeLayer(layerId);\n\n    if (layerId === this.id) {\n      if (this.group.caching) {\n        // Dirty every ID we're removing. Technically we might be able to avoid\n        // dirtying fields that have values in higher layers, but we don't have\n        // easy access to higher layers here, and we're about to recreate those\n        // layers anyway (see parent.addLayer below).\n        Object.keys(this.data).forEach(function (dataId) {\n          var ownStoreObject = _this.data[dataId];\n          var parentStoreObject = parent[\"lookup\"](dataId);\n\n          if (!parentStoreObject) {\n            // The StoreObject identified by dataId was defined in this layer\n            // but will be undefined in the parent layer, so we can delete the\n            // whole entity using this.delete(dataId). Since we're about to\n            // throw this layer away, the only goal of this deletion is to dirty\n            // the removed fields.\n            _this.delete(dataId);\n          } else if (!ownStoreObject) {\n            // This layer had an entry for dataId but it was undefined, which\n            // means the entity was deleted in this layer, and it's about to\n            // become undeleted when we remove this layer, so we need to dirty\n            // all fields that are about to be reexposed.\n            _this.group.dirty(dataId, \"__exists\");\n\n            Object.keys(parentStoreObject).forEach(function (storeFieldName) {\n              _this.group.dirty(dataId, storeFieldName);\n            });\n          } else if (ownStoreObject !== parentStoreObject) {\n            // If ownStoreObject is not exactly the same as parentStoreObject,\n            // dirty any fields whose values will change as a result of this\n            // removal.\n            Object.keys(ownStoreObject).forEach(function (storeFieldName) {\n              if (!equal(ownStoreObject[storeFieldName], parentStoreObject[storeFieldName])) {\n                _this.group.dirty(dataId, storeFieldName);\n              }\n            });\n          }\n        });\n      }\n\n      return parent;\n    } // No changes are necessary if the parent chain remains identical.\n\n\n    if (parent === this.parent) return this; // Recreate this layer on top of the new parent.\n\n    return parent.addLayer(this.id, this.replay);\n  };\n\n  Layer.prototype.toObject = function () {\n    return __assign(__assign({}, this.parent.toObject()), this.data);\n  };\n\n  Layer.prototype.findChildRefIds = function (dataId) {\n    var fromParent = this.parent.findChildRefIds(dataId);\n    return hasOwn.call(this.data, dataId) ? __assign(__assign({}, fromParent), _super.prototype.findChildRefIds.call(this, dataId)) : fromParent;\n  };\n\n  Layer.prototype.getStorage = function () {\n    var p = this.parent;\n\n    while (p.parent) p = p.parent;\n\n    return p.getStorage.apply(p, // @ts-expect-error\n    arguments);\n  };\n\n  return Layer;\n}(EntityStore); // Represents a Layer permanently installed just above the Root, which allows\n// reading optimistically (and registering optimistic dependencies) even when\n// no optimistic layers are currently active. The stump.group CacheGroup object\n// is shared by any/all Layer objects added on top of the Stump.\n\n\nvar Stump =\n/** @class */\nfunction (_super) {\n  __extends(Stump, _super);\n\n  function Stump(root) {\n    return _super.call(this, \"EntityStore.Stump\", root, function () {}, new CacheGroup(root.group.caching, root.group)) || this;\n  }\n\n  Stump.prototype.removeLayer = function () {\n    // Never remove the Stump layer.\n    return this;\n  };\n\n  Stump.prototype.merge = function (older, newer) {\n    // We never want to write any data into the Stump, so we forward any merge\n    // calls to the Root instead. Another option here would be to throw an\n    // exception, but the toReference(object, true) function can sometimes\n    // trigger Stump writes (which used to be Root writes, before the Stump\n    // concept was introduced).\n    return this.parent.merge(older, newer);\n  };\n\n  return Stump;\n}(Layer);\n\nfunction storeObjectReconciler(existingObject, incomingObject, property) {\n  var existingValue = existingObject[property];\n  var incomingValue = incomingObject[property]; // Wherever there is a key collision, prefer the incoming value, unless\n  // it is deeply equal to the existing value. It's worth checking deep\n  // equality here (even though blindly returning incoming would be\n  // logically correct) because preserving the referential identity of\n  // existing data can prevent needless rereading and rerendering.\n\n  return equal(existingValue, incomingValue) ? existingValue : incomingValue;\n}\n\nexport function supportsResultCaching(store) {\n  // When result caching is disabled, store.depend will be null.\n  return !!(store instanceof EntityStore && store.group.caching);\n}","map":{"version":3,"sources":["../../../src/cache/inmemory/entityStore.ts"],"names":[],"mappings":";AAAA,SAAS,SAAT,QAA0B,kCAA1B;AAEA,SAAS,GAAT,QAAoB,UAApB;AACA,SAAS,KAAT,QAAsB,eAAtB;AACA,SAAS,IAAT,QAAqB,WAArB;AAOA,SACE,WADF,EAEE,aAFF,EAGE,UAHF,EAIE,eAJF,EAKE,aALF,EAME,eANF,QAOO,0BAPP;AASA,SAAS,MAAT,EAAiB,sBAAjB,QAA+C,cAA/C;AAeA,IAAM,MAAM,GAAmB,MAAM,CAAC,MAAP,CAAc,IAAd,CAA/B;;AACA,IAAM,WAAW,GAAkB,YAAA;AAAM,SAAA,MAAA;AAAM,CAA/C;;AACA,IAAM,UAAU,GAAuB,MAAM,CAAC,MAAP,CAAc,IAAd,CAAvC;;AAEA,IAAA,WAAA;AAAA;AAAA,YAAA;AAGE,WAAA,WAAA,CACkB,QADlB,EAEkB,KAFlB,EAEmC;AAFnC,QAAA,KAAA,GAAA,IAAA;;AACkB,SAAA,QAAA,GAAA,QAAA;AACA,SAAA,KAAA,GAAA,KAAA;AAJR,SAAA,IAAA,GAA8B,MAAM,CAAC,MAAP,CAAc,IAAd,CAA9B,CAIyB,CAyXnC;AACA;AACA;;AACQ,SAAA,OAAA,GAEJ,MAAM,CAAC,MAAP,CAAc,IAAd,CAFI,CA5X2B,CAubnC;;AACQ,SAAA,IAAA,GAEJ,MAAM,CAAC,MAAP,CAAc,IAAd,CAFI,CAxb2B,CAqenC;AACA;;AACO,SAAA,aAAA,GAAgB,UACrB,iBADqB,EAErB,cAFqB,EAEC;AAEtB,aAAA,eAAe,CACb,WAAW,CAAC,iBAAD,CAAX,GACE,KAAI,CAAC,GAAL,CAAS,iBAAiB,CAAC,KAA3B,EAAkC,cAAlC,CADF,GAEE,iBAAiB,IAAI,iBAAiB,CAAC,cAAD,CAH3B,CAAf;AAIoB,KARf,CAve4B,CAifnC;AACA;AACA;;;AACO,SAAA,OAAA,GAA2B,UAAC,QAAD,EAAS;AACzC,aAAO,WAAW,CAAC,QAAD,CAAX,GACH,KAAI,CAAC,GAAL,CAAS,QAAQ,CAAC,KAAlB,CADG,GAEH,OAAO,QAAP,KAAoB,QAFxB;AAGD,KAJM,CApf4B,CA0fnC;AACA;AACA;AACA;;;AACO,SAAA,WAAA,GAAmC,UAAC,YAAD,EAAe,cAAf,EAA6B;AACrE,UAAI,OAAO,YAAP,KAAwB,QAA5B,EAAsC;AACpC,eAAO,aAAa,CAAC,YAAD,CAApB;AACD;;AAED,UAAI,WAAW,CAAC,YAAD,CAAf,EAA+B;AAC7B,eAAO,YAAP;AACD;;AAEM,UAAA,EAAE,GAAI,KAAI,CAAC,QAAL,CAAc,QAAd,CAAuB,YAAvB,EAAJ,CAAI,CAAN;;AAEP,UAAI,EAAJ,EAAQ;AACN,YAAM,GAAG,GAAG,aAAa,CAAC,EAAD,CAAzB;;AACA,YAAI,cAAJ,EAAoB;AAClB,UAAA,KAAI,CAAC,KAAL,CAAW,EAAX,EAAe,YAAf;AACD;;AACD,eAAO,GAAP;AACD;AACF,KAlBM;AA7fH,GANN,CAeE;AACA;AACA;;;AAEO,EAAA,WAAA,CAAA,SAAA,CAAA,QAAA,GAAP,YAAA;AACE,WAAA,QAAA,CAAA,EAAA,EAAY,KAAK,IAAjB,CAAA;AACD,GAFM;;AAIA,EAAA,WAAA,CAAA,SAAA,CAAA,GAAA,GAAP,UAAW,MAAX,EAAyB;AACvB,WAAO,KAAK,MAAL,CAAY,MAAZ,EAAoB,IAApB,MAA8B,KAAK,CAA1C;AACD,GAFM;;AAIA,EAAA,WAAA,CAAA,SAAA,CAAA,GAAA,GAAP,UAAW,MAAX,EAA2B,SAA3B,EAA4C;AAC1C,SAAK,KAAL,CAAW,MAAX,CAAkB,MAAlB,EAA0B,SAA1B;;AACA,QAAI,MAAM,CAAC,IAAP,CAAY,KAAK,IAAjB,EAAuB,MAAvB,CAAJ,EAAoC;AAClC,UAAM,WAAW,GAAG,KAAK,IAAL,CAAU,MAAV,CAApB;;AACA,UAAI,WAAW,IAAI,MAAM,CAAC,IAAP,CAAY,WAAZ,EAAyB,SAAzB,CAAnB,EAAwD;AACtD,eAAO,WAAW,CAAC,SAAD,CAAlB;AACD;AACF;;AACD,QACE,SAAS,KAAK,YAAd,IACA,MAAM,CAAC,IAAP,CAAY,KAAK,QAAL,CAAc,iBAA1B,EAA6C,MAA7C,CAFF,EAGE;AACA,aAAO,KAAK,QAAL,CAAc,iBAAd,CAAgC,MAAhC,CAAP;AACD;;AACD,QAAI,gBAAgB,KAApB,EAA2B;AACzB,aAAO,KAAK,MAAL,CAAY,GAAZ,CAAgB,MAAhB,EAAwB,SAAxB,CAAP;AACD;AACF,GAjBM;;AAmBG,EAAA,WAAA,CAAA,SAAA,CAAA,MAAA,GAAV,UACE,MADF,EAEE,iBAFF,EAE6B;AAE3B;AACA;AACA;AACA;AACA;AACA,QAAI,iBAAJ,EAAuB,KAAK,KAAL,CAAW,MAAX,CAAkB,MAAlB,EAA0B,UAA1B;;AAEvB,QAAI,MAAM,CAAC,IAAP,CAAY,KAAK,IAAjB,EAAuB,MAAvB,CAAJ,EAAoC;AAClC,aAAO,KAAK,IAAL,CAAU,MAAV,CAAP;AACD;;AAED,QAAI,gBAAgB,KAApB,EAA2B;AACzB,aAAO,KAAK,MAAL,CAAY,MAAZ,CAAmB,MAAnB,EAA2B,iBAA3B,CAAP;AACD;;AAED,QAAI,KAAK,QAAL,CAAc,iBAAd,CAAgC,MAAhC,CAAJ,EAA6C;AAC3C,aAAO,MAAM,CAAC,MAAP,CAAc,IAAd,CAAP;AACD;AACF,GAtBS;;AAwBH,EAAA,WAAA,CAAA,SAAA,CAAA,KAAA,GAAP,UAAa,KAAb,EAA0C,KAA1C,EAAqE;AAArE,QAAA,KAAA,GAAA,IAAA;;AACE,QAAI,MAAJ,CADmE,CAGnE;;AACA,QAAI,WAAW,CAAC,KAAD,CAAf,EAAwB,KAAK,GAAG,KAAK,CAAC,KAAd;AACxB,QAAI,WAAW,CAAC,KAAD,CAAf,EAAwB,KAAK,GAAG,KAAK,CAAC,KAAd;AAExB,QAAM,QAAQ,GACZ,OAAO,KAAP,KAAiB,QAAjB,GAA4B,KAAK,MAAL,CAAa,MAAM,GAAG,KAAtB,CAA5B,GAA4D,KAD9D;AAGA,QAAM,QAAQ,GACZ,OAAO,KAAP,KAAiB,QAAjB,GAA4B,KAAK,MAAL,CAAa,MAAM,GAAG,KAAtB,CAA5B,GAA4D,KAD9D,CAVmE,CAanE;AACA;;AACA,QAAI,CAAC,QAAL,EAAe;AAEf,IAAA,SAAS,CAAC,OAAO,MAAP,KAAkB,QAAnB,EAA6B,CAA7B,CAAT;AAEA,QAAM,MAAM,GAAgB,IAAI,UAAJ,CAAe,qBAAf,EAAsC,KAAtC,CAC1B,QAD0B,EAE1B,QAF0B,CAA5B,CAnBmE,CAwBnE;AACA;;AACA,SAAK,IAAL,CAAU,MAAV,IAAoB,MAApB;;AAEA,QAAI,MAAM,KAAK,QAAf,EAAyB;AACvB,aAAO,KAAK,IAAL,CAAU,MAAV,CAAP;;AACA,UAAI,KAAK,KAAL,CAAW,OAAf,EAAwB;AACtB,YAAM,eAAa,GAAsB,MAAM,CAAC,MAAP,CAAc,IAAd,CAAzC,CADsB,CAGtB;AACA;AACA;;AACA,YAAI,CAAC,QAAL,EAAe,eAAa,CAAC,QAAd,GAAyB,CAAzB,CANO,CAQtB;AACA;;AACA,QAAA,MAAM,CAAC,IAAP,CAAY,QAAZ,EAAsB,OAAtB,CAA8B,UAAC,cAAD,EAAe;AAC3C,cACE,CAAC,QAAD,IACA,QAAQ,CAAC,cAAD,CAAR,KAA6B,MAAM,CAAC,cAAD,CAFrC,EAGE;AACA;AACA;AACA,YAAA,eAAa,CAAC,cAAD,CAAb,GAAgC,CAAhC,CAHA,CAKA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,gBAAM,SAAS,GAAG,sBAAsB,CAAC,cAAD,CAAxC;;AACA,gBACE,SAAS,KAAK,cAAd,IACA,CAAC,KAAI,CAAC,QAAL,CAAc,UAAd,CAAyB,MAAM,CAAC,UAAhC,EAA4C,SAA5C,CAFH,EAGE;AACA,cAAA,eAAa,CAAC,SAAD,CAAb,GAA2B,CAA3B;AACD,aAlBD,CAoBA;AACA;AACA;;;AACA,gBAAI,MAAM,CAAC,cAAD,CAAN,KAA2B,KAAK,CAAhC,IAAqC,EAAE,KAAI,YAAY,KAAlB,CAAzC,EAAmE;AACjE,qBAAO,MAAM,CAAC,cAAD,CAAb;AACD;AACF;AACF,SA/BD;;AAiCA,YACE,eAAa,CAAC,UAAd,IACA,EAAE,QAAQ,IAAI,QAAQ,CAAC,UAAvB,CADA,IAEA;AACA;AACA;AACA;AACA,aAAK,QAAL,CAAc,iBAAd,CAAgC,MAAhC,MAA4C,MAAM,CAAC,UAPrD,EAQE;AACA,iBAAO,eAAa,CAAC,UAArB;AACD;;AAED,QAAA,MAAM,CAAC,IAAP,CAAY,eAAZ,EAA2B,OAA3B,CAAmC,UAAC,SAAD,EAAU;AAC3C,iBAAA,KAAI,CAAC,KAAL,CAAW,KAAX,CAAiB,MAAjB,EAAmC,SAAnC,CAAA;AAA6C,SAD/C;AAGD;AACF;AACF,GA1FM;;AA4FA,EAAA,WAAA,CAAA,SAAA,CAAA,MAAA,GAAP,UACE,MADF,EAEE,MAFF,EAEwD;AAFxD,QAAA,KAAA,GAAA,IAAA;;AAIE,QAAM,WAAW,GAAG,KAAK,MAAL,CAAY,MAAZ,CAApB;;AAEA,QAAI,WAAJ,EAAiB;AACf,UAAM,eAAa,GAAwB,MAAM,CAAC,MAAP,CAAc,IAAd,CAA3C;AACA,UAAI,aAAW,GAAG,KAAlB;AACA,UAAI,YAAU,GAAG,IAAjB;AAEA,UAAM,eAAa,GAAG;AACpB,QAAA,MAAM,EAAA,MADc;AAEpB,QAAA,UAAU,EAAA,UAFU;AAGpB,QAAA,WAAW,EAAA,WAHS;AAIpB,QAAA,WAAW,EAAE,KAAK,WAJE;AAKpB,QAAA,OAAO,EAAE,KAAK,OALM;AAMpB,QAAA,SAAS,EAAE,UACT,kBADS,EAET,IAFS,EAEqB;AAE9B,iBAAA,KAAI,CAAC,QAAL,CAAc,SAAd,CACE,OAAO,kBAAP,KAA8B,QAA9B,GACE;AACE,YAAA,SAAS,EAAE,kBADb;AAEE,YAAA,IAAI,EAAE,IAAI,IAAI,aAAa,CAAC,MAAD;AAF7B,WADF,GAKE,kBANJ,EAOE;AAAE,YAAA,KAAK,EAAE;AAAT,WAPF,CAAA;AAQC;AAlBiB,OAAtB;AAqBA,MAAA,MAAM,CAAC,IAAP,CAAY,WAAZ,EAAyB,OAAzB,CAAiC,UAAC,cAAD,EAAe;AAC9C,YAAM,SAAS,GAAG,sBAAsB,CAAC,cAAD,CAAxC;AACA,YAAI,UAAU,GAAG,WAAW,CAAC,cAAD,CAA5B;AACA,YAAI,UAAU,KAAK,KAAK,CAAxB,EAA2B;AAC3B,YAAM,MAAM,GACV,OAAO,MAAP,KAAkB,UAAlB,GAA+B,MAA/B,GACE,MAAM,CAAC,cAAD,CAAN,IAA0B,MAAM,CAAC,SAAD,CAFpC;;AAIA,YAAI,MAAJ,EAAY;AACV,cAAI,QAAQ,GACV,MAAM,KAAK,WAAX,GAAyB,MAAzB,GACE,MAAM,CAAC,eAAe,CAAC,UAAD,CAAhB,EAA4B,QAAA,CAAA,QAAA,CAAA,EAAA,EAC7B,eAD6B,CAAA,EAChB;AAChB,YAAA,SAAS,EAAA,SADO;AAEhB,YAAA,cAAc,EAAA,cAFE;AAGhB,YAAA,OAAO,EAAE,KAAI,CAAC,UAAL,CAAgB,MAAhB,EAAwB,cAAxB;AAHO,WADgB,CAA5B,CAFV;;AASA,cAAI,QAAQ,KAAK,UAAjB,EAA6B;AAC3B,YAAA,KAAI,CAAC,KAAL,CAAW,KAAX,CAAiB,MAAjB,EAAyB,cAAzB;AACD,WAFD,MAEO;AACL,gBAAI,QAAQ,KAAK,MAAjB,EAAyB,QAAQ,GAAG,KAAK,CAAhB;;AACzB,gBAAI,QAAQ,KAAK,UAAjB,EAA6B;AAC3B,cAAA,eAAa,CAAC,cAAD,CAAb,GAAgC,QAAhC;AACA,cAAA,aAAW,GAAG,IAAd;AACA,cAAA,UAAU,GAAG,QAAb;;AAEA,kBAAI,UAAU,CAAA,OAAV,KAAU,KAAd,EAAc;AACZ,oBAAM,cAAc,GAAG,UAAC,GAAD,EAAe;AACpC,sBAAI,KAAI,CAAC,MAAL,CAAY,GAAG,CAAC,KAAhB,MAA2B,SAA/B,EAA0C;AACxC,oBAAA,UAAU,CAAA,OAAV,KACE,KADF,IACE,SAAA,CAAA,IAAA,CAAA,CAAA,EAAA,GAAA,CADF;AAEI,2BAAA,IAAA;AACA;AAGJ,iBARJ;;oBASE,WAAC,CAAA,QAAA,C,EAAA;AACD,kBAAA,cAAA,CAAA,QAAA,CAAA;AACF,iB,MACE,IAAA,KAAA,CAAA,OAAA,CAAe,QAAf,CAAA,EAAyB;AAC1B;AAAM,sBAAA,aAAU,GAAQ,KAAlB;AACL,sBAAA,gBAAA,GAAA,KAAA,CAAA;;AACA,uBAAI,IAAA,EAAA,GAAA,CAAA,EAAa,UAAkB,GAAA,QAAnC,EAAmC,EAAA,GAAA,UAAA,CAAA,MAAnC,EAAmC,EAAA,EAAnC,EAAmC;AAC/B,wBAAA,KAAA,GAAA,UAAgB,CAAA,EAAA,CAAhB;;AACJ,wBAAoB,WAAA,CAAA,KAAA,CAApB,EAAoB;AAAT,sBAAA,aAAK,GAAA,IAAL;AACL,0BAAA,cAAkB,CAAA,KAAA,CAAlB,EACF;AACA,qBAHJ,MAG+B;AAC5B;AAAM;AACL,0BAAA,OAAA,KAAA,KAAA,QAAA,IAAA,CAAA,CAAA,KAAA,EAAA;AACA,4BAAA,EAAA,GAAA,KAAA,CAAA,QAAA,CAAA,QAAA,CAAA,KAAA,EAAA,CAAA,CAAA,CADA,CAEI;;;AACK,4BAAA,EAAA,EAAE;AACT,0BAAA,gBAAA,GAAA,KAAA;AACA;AACE;AACF;;wBACF,aAAC,IAAA,gBAAA,KAAA,S,EAAA;AACF,sBAAA,UAAA,CAAA,OAAA,KAAA,KAAA,IAAA,SAAA,CAAA,IAAA,CAAA,CAAA,EAAA,gBAAA,CAAA;AACG;AACF;AAEI;AAGJ;AACF;AACF;AACF;AACF;;YACF,UAAC,KAAA,KAAA,C,EAAA;AACH,UAAA,YAAC,GAAA,KAAD;AACD;AACD,OA1EF;;UA2EI,a,EAAA;AACF,aAAC,KAAD,CAAC,MAAD,EAAC,eAAD;;AACC,YAAA,YAAA,EAAA;AAEC,cAAA,gBAAc,KAAd,EAAc;AACX,iBAAM,IAAN,CAAY,MAAZ,IAAc,KAAA,CAAd;AAED,WAHF,MAII;AACF,mBAAK,KAAK,IAAL,CAAY,MAAZ,CAAL;AACD;;eAAM,K,CAAC,K,CAAA,M,EAAA,U;AACN;;AACF,eAAC,IAAD;AACA;AACF;;WAEA,K;AACF,GA5HG,CAlKT,CA+RI;AAEA;AACF;AAEA;AACA;AACA;;;AACA,EAAA,WAAA,CAAA,SAAA,CAAA,MAAA,GAAA,UAAA,MAAA,EAAA,SAAA,EAAA,IAAA,EAAA;AACA,QAAA,EAAA;;AACA,QAAA,WAAA,GAAA,KAAA,MAAA,CAAA,MAAA,CAAA;;AACO,QAAA,WAAA,EAAP;;AAKQ,UAAA,cAAkB,GAAC,SAAO,IAAQ,IAAf,GACrB,KAAA,QAAA,CAAc,iBAAd,CAAc;AAAA,QAAA,QAAA,EAAA,QAAA;AAAA,QAAA,SAAA,EAAA,SAAA;AAAA,QAAA,IAAA,EAAA;AAAA,OAAd,CADqB,GAEjB,SAFF;AAGJ,aAAM,KAAA,MAAA,CAAc,MAAd,EACJ,cAAmB,IAAA,EAAA,GAAA,EAAA,EACjB,EAAA,CAAA,cAAA,CAAA,GAAc,WADG,EAEnB,EAFmB,IAEjB,WAHE,CAAN;AAIA;;WAIM,K;AAEJ,GArBN;;AAuBE,EAAA,WAAC,CAAA,SAAD,CAAC,KAAD,GAAC,UAAA,OAAA,EAAA,KAAA,EAAA;AACD,QAAA,OAAO,GAAM,KAAb;;AACD,QAAA,OAAA,CAAA,EAAA,EAAA;AAEM,UAAA,MAAA,CAAA,IAAA,CAAA,KAAP,IAAO,EAAP,OAAa,CAAA,EAAN,CAAA,EAAiC;AAClC,QAAA,OAAU,GAAA,KAAM,MAAN,CAAM,OAAA,CAAA,EAAN,EAAM,OAAA,CAAA,SAAN,EAAM,OAAA,CAAA,IAAN,CAAV;AACA;;AACF,UAAI,gBAAgB,KAAhB,IAAuB,SAAW,KAAtC,EAAyC;AACvC,QAAA,OAAO,GAAG,KAAK,MAAL,CAAY,KAAZ,CAAY,OAAZ,EAAwB,KAAxB,KAAgC,OAA1C;AACD,OAPJ,CAQG;AACE;AACF;AACA;;;AACA,UAAA,OAAA,CAAA,SAAA,IAAA,OAAA,EAAA;AACA,aAAA,KAAA,CAAA,KAAA,CAAA,OAAA,CAAA,EAAA,EAAA,OAAA,CAAA,SAAA,IAAA,UAAA;AACA;AACA;;WACE,O;AACF,GAnBF;;AAoBA,EAAA,WAAC,CAAA,SAAD,CAAC,KAAD,GAAC,YAAA;AACD,SAAA,OAAA,CAAO,IAAP;AACD,GAFC;;AAIK,EAAA,WAAA,CAAA,SAAA,CAAP,OAAO,GAAP,YAAA;AACE,QAAI,KAAC,GAAO,IAAZ;;AACD,QAAA,GAAA,GAAA,KAAA,QAAA,EAAA;AAEM,QAAA,YAAA,GAAP,EAAO;AAAP,SAAA,YAAA,GAYC,OAZD,CAYC,UAAA,EAAA,EAAA;AAXO,UAAG,CAAA,MAAQ,CAAA,IAAR,CAAQ,KAAW,CAAA,QAAX,CAAW,iBAAnB,EAAmB,EAAnB,CAAH,EAAsB;AACtB,QAAA,YAAyB,CAAE,IAA3B,CAA4B,EAA5B;AACD;AACH,KAJJ;;QAKM,YAAA,CAAA,M,EAAiB;AACnB,MAAA,GAAC,CAAA,MAAD,GAAC;AAAA,QAAA,YAAA,EAAA,YAAA,CAAA,IAAA;AAAA,OAAD;AACD;;AACD,WAAI,GAAJ;AACE,GAbG;;AAcL,EAAA,WAAC,CAAA,SAAD,CAAC,OAAD,GAAC,UAAA,OAAA,EAAA;AACD,QAAA,KAAO,GAAI,IAAX;;AACD,IAAA,MAAA,CAAA,IAAA,CAAA,KAAA,IAAA,EAAA,OAAA,CAAA,UAAA,MAAA,EAAA;AAEM,UAAA,EAAA,OAAA,IAAA,MAAO,CAAd,IAAO,CAAP,OAAO,EAAQ,MAAR,CAAA,CAAA,EAA6C;AAApD,QAAA,KAAA,CAAA,MAAA,CAeC,MAfD;AACE;AACE,KAJH;;QAKK,O,EAAI;AACN,UAAC,MAAA,GAAA,OAAA,CAAA,MAAD;AAAA,UAAC,MAAA,GAAA,MAAA,CAAA,OAAA,EAAA,CAAA,QAAA,CAAA,CAAD;;AACC,MAAA,MAAA,CAAA,IAAA,CAAA,MAAA,EAAA,OAAA,CAAA,UAAA,MAAA,EAAA;AACC,QAAA,KAAS,CAAC,KAAV,CAAU,MAAV,EAAU,MAAA,CAAA,MAAA,CAAV;AACI,OAFL;;AAGD,UAAA,MAAA,EAAY;AACV,QAAA,MAAK,CAAA,YAAL,CAAmB,OAAnB,CAAwB,KAAM,MAA9B,EAAgD,IAAhD;AACD;AACD;AACE,GAhBJ;;AAiBE,EAAA,WAAC,CAAA,SAAD,CAAC,MAAD,GAAC,UAAA,MAAA,EAAA;AACH,WAAC,KAAA,OAAA,CAAA,MAAA,IAAA,CAAA,KAAA,OAAA,CAAA,MAAA,KAAA,CAAA,IAAA,CAAD;AACD,GAFG;;AAgBG,EAAA,WAAA,CAAA,SAAA,CAAP,OAAO,GAAP,UAAc,MAAd,EAA4B;AAC1B,QAAA,KAAQ,OAAR,CAAa,MAAb,IAA2B,CAA3B,EAA4B;AAC7B,UAAA,KAAA,GAAA,EAAA,KAAA,OAAA,CAAA,MAAA,CAAA;AAEM,UAAA,CAAP,KAAO,EACG,OAAC,KAAQ,OAAR,CAAmB,MAAnB,CAAD;AACN,aAAM,KAAN;AACA;;WAAY,C;AACZ,GARG,CArYT,CA8YI;AACA;;;AACF,EAAA,WAAC,CAAA,SAAD,CAAC,YAAD,GAAC,UAAA,GAAA,EAAA;AAED,QAAA,GAAA,KAAA,KAAA,CAAA,EAAA;AAAA,MAAA,GAAA,GAAA,IAAA,GAAA,EAAA;AAAA;;AACA,IAAA,MAAA,CAAA,IAAA,CAAA,KAAA,OAAA,EAAA,OAAA,CAAA,GAAA,CAAA,GAAA,EAAA,GAAA;;AACO,QAAA,gBAAA,KAAA,EAAP;AAAoB,WAAA,MAAA,CAAA,YAAA,CAAA,GAAA;AAClB,KADK,MAED;AACF;AACD;AAAM;AACL,MAAA,MAAA,CAAA,IAAA,CAAA,KAAA,QAAA,CAAA,iBAAA,EAAA,OAAA,CAAA,GAAA,CAAA,GAAA,EAAA,GAAA;AACA;;AACA,WAAA,GAAA;AACA,GAZJ,CAhZF,CA6ZI;AACA;AACF;AAEA;;;AACA,EAAA,WAAA,CAAA,SAAA,CAAA,EAAA,GAAA,YAAA;AACA,QAAA,KAAA,GAAA,IAAA;;AACA,QAAA,GAAA,GAAA,KAAA,YAAA,EAAA;AACO,QAAA,QAAA,GAAA,KAAP,QAAO,EAAA;AAAP,IAAA,GAAA,CAAA,OAAA,CAAA,UAqBC,EArBD,EAqBC;AApBO,UAAG,MAAO,CAAC,IAAR,CAAQ,QAAR,EAAuB,EAAvB,CAAH,EAA0B;AAC1B;AACF;AACE;AACF,QAAA,MAAA,CAAA,IAAA,CAAA,KAAA,CAAA,eAAA,CAAA,EAAA,CAAA,EAAA,OAAA,CAAA,GAAA,CAAA,GAAA,EAAA,GAAA,EAJ4B,CAK5B;AACA;;AACA,eAAO,QAAK,CAAA,EAAA,CAAZ;AACA;AACA,KAVN;QAWM,WAAO,GAAA,MAAS,CAAA,IAAT,CAAa,QAAb,C;;QACT,WAAC,CAAA,M,EAAA;AACA,UAAA,MAAA,GAAA,IAAA;;AACG,aAAA,MAAW,YAAc,KAAzB,EACF,MAAA,GAAY,MAAM,CAAE,MAApB;;AACF,MAAA,WAAQ,CAAA,OAAR,CAA6B,UAAA,EAAA,EAAA;AAAA,eAAA,MAAA,CAAA,MAAA,CAAA,EAAA,CAAA;AAAA,OAA7B;AACA;;WAA8B,W;AAC9B,GArBJ;;AAsBE,EAAA,WAAC,CAAA,SAAD,CAAC,eAAD,GAAC,UAAA,MAAA,EAAA;AACD,QAAA,CAAA,MAAO,CAAA,IAAP,CAAO,KAAY,IAAnB,EAAmB,MAAnB,CAAA,EAAmB;AACpB,UAAA,OAAA,GAAA,KAAA,IAAA,CAAA,MAAA,IAAA,MAAA,CAAA,MAAA,CAAA,IAAA,CAAA;AAOM,UAAA,IAAA,GAAA,KAAA,IAAA,CAAP,MAAO,CAAA;AACD,UAAC,CAAA,IAAD,EACI,OAAK,OAAL;AACN,UAAM,SAAO,GAAK,IAAI,GAAJ,CAAK,CAAA,IAAA,CAAL,CAAlB,CAXiB,CAYjB;AAAW;;AAEX,MAAA,SAAM,CAAA,OAAN,CAAgB,UAAuC,GAAvC,EAA8C;AAC9D,YAAA,WAAA,CAAA,GAAA,CAAA,EAAA;AACA,UAAA,OAAA,CAAA,GAAA,CAAA,KAAA,CAAA,GAAA,IAAA,CADA,CAEA;AACM;AACF;AACA;AACA;AACA;AACA;AACA;;YACA,eAAA,CAAA,GAAA,C,EAAA;AACA,UAAA,MAAA,CAAA,IAAA,CAAA,GAAA,EAAA,OAAA,CAAA,UAAA,GAAA,EAAA;AACD,gBAAA,KAAA,GAAA,GAAA,CAAA,GAAA,CAAA,CADC,CAEE;AACF;;AACE,gBAAM,eAAe,CAAC,KAAD,CAArB,EAAuB;AACvB,cAAA,SAAA,CAAA,GAAA,CAAA,KAAA;AACA;AACA,WAPF;AAQI;AACF,OArBN;AAsBI;;WACF,KAAC,IAAD,CAAC,MAAD,C;AACF,GAvCF;;AAwCA,EAAA,WAAC,CAAA,SAAD,CAAC,YAAD,GAAC,YAAA;AACD,WAAO,KAAK,KAAL,CAAU,QAAV,CAAkB,WAAlB,CAAkB,SAAlB,CAAP;AACD,GAFC;;AAMK,SAAP,WAAO;AACL,CAveJ,EAAA;;AAweE,SAAC,WAAD,G,CA8CF;AAthBA;;AA0hBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,IAAA,UAAA;AAAA;AAAA,YAAA;AACA,WAAA,UAAA,CAAA,OAAA,EAAA,MAAA,EAAA;AACA,QAAA,MAAA,KAAA,KAAA,CAAA,EAAA;AAAA,MAAA,MAAA,GAAA,IAAA;AAAA;;AACA,SAAA,OAAA,GAAA,OAAA;AAOE,SAAA,MAAA,GAAA,MAAA;AAEU,SAAA,CAAA,GAAA,IAAA;AADQ,SAAA,YAAA;AACR;;AARF,EAAA,UAAC,CAAA,SAAD,CAAsD,YAAtD,GAAsD,YAAA;AAU5D,SAAK,CAAL,GAAK,KAAA,OAAA,GAAe,GAAA,EAAf,GAAe,IAApB;AACD,SAAA,QAAA,GAAA,IAAA,IAAA,CAAA,aAAA,CAAA;AAED,GAbQ;;AAcN,EAAA,UAAM,CAAA,SAAN,CAAc,MAAd,GAAwB,UAAoB,MAApB,EAAqB,cAArB,EAAqB;AAC7C,QAAI,KAAC,CAAL,EAAK;AACN,WAAA,CAAA,CAAA,UAAA,CAAA,MAAA,EAAA,cAAA,CAAA;AAEM,UAAA,SAAA,GAAP,sBAA4B,CAAA,cAAA,CAArB;;AACD,UAAI,SAAK,KAAA,cAAT,EAAS;AACP;AACE;AACF;AACF;AACA;AACA,aAAA,CAAA,CAAA,UAAA,CAAA,MAAA,EAAA,SAAA,CAAA;AACA;;UACA,KAAA,M,EAAA;AACA,aAAK,MAAL,CAAO,MAAP,CAAkB,MAAlB,EAA0B,cAA1B;AACD;AACD;AACE,GAjBJ;;AAkBE,EAAA,UAAC,CAAA,SAAD,CAAC,KAAD,GAAC,UAAA,MAAA,EAAA,cAAA,EAAA;AACH,QAAC,KAAA,CAAD,EAAC;AACF,WAAA,CAAA,CAAA,KAAA,CAAA,UAAA,CAAA,MAAA,EAAA,cAAA,CAAA,EAED;AACM;AACF;AAEE;AACA;AACA;AACA;AACA,MAAA,cAAA,KAAA,UAAA,GAAA,QAAA,GAAA,UAVL;AAWK;AACA,GAdF;;SAeE,U;AAEJ,CArDJ,EAAA;;AAsDE,SAAC,UAAD,CAAC,MAAD,EAAC,cAAD,EAAC;AACH;AAAC;AAED;AACE,SAAA,cAAA,GAAA,GAAA,GAAA,MAAA;AACA;;AACA,OAAA,SAAA,8BAAA,CAAA,KAAA,EAAA,QAAA,EAAoD;AACpD,MAAA,qBAAwB,CAAA,KAAA,CAAxB,EAA8B;AAC/B;AAEK;AAIA;AACF;AACA;AACA;AACA;AACA;AACA,IAAA,KAAA,CAAA,KAAA,CAAA,MAAA,CAAA,QAAA,EAAA,UAAA;AACA;AACA;;CACA,UAAA,WAAA,EAAY;AACd;AACD,MAAA,IAAA;AAAA;AAAA,YAAA,MAAA,EAAA;AAED,IAAA,SAAiB,CAAA,IAAA,EAAW,MAAX,CAAjB;;AACE,aAAA,IAAA,CAAA,EAAA,EAAA;AACA,UAAA,QAAA,GAAA,EAAA,CAAA,QAAA;AAAA,UAAA,EAAA,GAAA,EAAA,CAAA,aAAA;AAAA,UAAA,aAAA,GAAA,EAAA,KAAA,KAAA,CAAA,GAAA,IAAA,GAAA,EAAA;AAAA,UAAA,IAAA,GAAA,EAAA,CAAA,IAAA;;AAA0B,UAAA,KAAA,GAAA,MAAA,CAAA,IAAA,CAAW,IAAX,EAAW,QAAX,EAAW,IAAA,UAAA,CAAA,aAAA,CAAX,KAAW,IAAX;;AACxB,MAAA,KAAA,CAAA,KAAA,GAQC,IAAA,KAAA,CAAA,KAAA,CARD;AACE,MAAA,KAAA,CAAA,WAAA,GAAQ,IAAA,IAAA,CACR,aADQ,CAAR;AAQA,UAAA,IAAA,EAIc,KAAA,CAAA,OAAA,CAAY,IAAZ;AAiBA,aAAA,KAAA;AApBd;;SAAU,S,CAAK,Q,GAAY,UAAE,OAAF,EAAE,MAAF,EAAE;;AAC9B;AAID;AAIE,aAAA,KAAA,KAAA,CAAA,QAAA,CAAA,OAAA,EAAA,MAAA,CAAA;AACA,K;;QACA,CAAA,S,CAAA,W,GAAA,YAAA;AACA;AACD,aAAA,IAAA;AAED,K;;QACE,CAAA,S,CAAA,U,GAAA,YAA+B;AAC/B,aAAO,KAAK,WAAL,CAAK,WAAL,CAAK,SAAL,CAAP;AACD,K;;AAGM,WAAP,IAAO;GApCV,CAqCK,WArCL,CAAA;;AAsCG,EAAA,WAAC,CAAA,IAAD,GAAC,IAAD;GACF,WAAA,KAAC,WAAA,GAAA,EAAD,C,GAnCA;AAAa;;;AAFE,IAAA,KAAA;AAAA;AAAA,UAAW,MAAX,EAsChB;AAED,EAAA,SAAA,CAAA,KAAA,EAAA,MAAA,CAAA;;AACA,WAAA,KAAA,CAAA,EAAA,EAAA,MAAA,EAAA,MAAA,EAAiC,KAAjC,EAAiC;AACjC,QAAA,KAAA,GAAA,MAAA,CAAA,IAAA,CAAA,IAAA,EAAA,MAAA,CAAA,QAAA,EAAA,KAAA,KAAA,IAAA;;AAAoB,IAAA,KAAA,CAAA,EAAA,GAAA,EAAA;AAClB,IAAA,KAAA,CAAA,MAAA,GAEkB,MAFlB;AAME,IAAA,KAAA,CAAA,MAAA,GAAA,MAAA;AALgB,IAAA,KAAA,CAAA,KAAA,GAAU,KAAV;AACA,IAAA,MAAA,CAAA,KAAA,CAAA;AACA,WAAA,KAAA;AACA;;AAGhB,EAAA,KAAA,CAAA,SAAA,CAAW,QAAX,GAAa,UAAA,OAAA,EAAA,MAAA,EAAA;;AACd,GADC;;AAGK,EAAA,KAAA,CAAA,SAAA,CAAP,WAAO,GAAP,UAAgB,OAAhB,EAAiC;AAC/B,QAAA,KAAO,GAAI,IAAX,CAD+B,CAEhC;;;AAEM,QAAA,MAAA,GAAA,KAAA,MAAA,CAAP,WAAO,CAAY,OAAZ,CAAA;;AAAP,QAAA,OAAA,KAAA,KAuDC,EAvDD,EAuDC;AAtDC,UAAA,KAAA,KAAA,CAAA,OAAA,EAAA;AACM;AAEF;AACE;AACF;AACA,QAAA,MAAA,CAAA,IAAA,CAAA,KAAA,IAAA,EAAA,OAAA,CAAA,UAAA,MAAA,EAAA;AACA,cAAA,cAAA,GAAA,KAAA,CAAA,IAAA,CAAA,MAAA,CAAA;AACA,cAAA,iBAAA,GAAA,MAAA,CAAA,QAAA,CAAA,CAA6C,MAA7C,CAAA;;AACA,cAAO,CAAA,iBAAP,EAAuB;AACf;AACA;AACF;AACF;AACA;AACA,YAAA,KAAA,CAAA,MAAA,CAAA,MAAA;AACA,WAPJ,MAQI,IAAA,CAAA,cAAA,EAAsB;AACtB;AACD;AAAM;AACL;AACA,YAAA,KAAA,CAAA,KAAA,CAAA,KAAA,CAAA,MAAA,EAAA,UAAA;;AACA,YAAA,MAAA,CAAA,IAAA,CAAA,iBAAA,EAAA,OAAA,CAAA,UAAA,cAAA,EAAA;AACA,cAAA,KAAA,CAAA,KAAA,CAAA,KAAA,CAAA,MAAA,EAAA,cAAA;AACA,aAFA;AAGA,WARA,MASE,IAAA,cAAW,KAAM,iBAAjB,EAAyB;AAC3B;AACD;AAAM;AACL,YAAA,MAAA,CAAA,IAAA,CAAA,cAAA,EAAA,OAAA,CAAA,UAAA,cAAA,EAAA;AACA,kBAAA,CAAA,KAAA,CAAA,cAAA,CAAA,cAAA,CAAA,EAAA,iBAAgE,CAAA,cAAA,CAAhE,CAAA,EAAgE;AAChE,gBAAA,KAAW,CAAA,KAAX,CAAW,KAAX,CAAW,MAAX,EAAW,cAAX;AACA;AACE,aAJF;AAUI;AACF,SAlCN;AAmCI;;aACF,M;AACF,KAhD2B,CAiD7B;;;QAEA,MAAA,KAAO,KAAO,M,EACf,OAAA,IAAA,CApD8B,CAsD/B;;AACA,WAAI,MAAM,CAAA,QAAN,CAAgB,KAAM,EAAtB,EAAsB,KAAA,MAAtB,CAAJ;AAA4B,GAvDvB;;AAyDL,EAAA,KAAA,CAAA,SAAA,CAAA,QAAA,GAAA,YAAA;AACA,WAAO,QAAO,CAAA,QAAS,CAAA,EAAA,EAAK,KAAI,MAAJ,CAAS,QAAT,EAAL,CAAT,EAA+B,KAAA,IAA/B,CAAd;AACD,GAFC;;AAIK,EAAA,KAAA,CAAA,SAAA,CAAP,eAAO,GAAP,UAAA,MAAA,EAAA;AACE,QAAA,UAAA,GAAA,KAAA,MAAA,CACK,eADL,CACiB,MADjB,CAAA;AAID,WAAA,MAAA,CAAA,IAAA,CAAA,KAAA,IAAA,EAAA,MAAA,IAAA,QAAA,CAAA,QAAA,CAAA,EAAA,EAAA,UAAA,CAAA,EAAA,MAAA,CAAA,SAAA,CAAA,eAAA,CAAA,IAAA,CAAA,IAAA,EAAA,MAAA,CAAA,CAAA,GAAA,UAAA;AAED,GAPO;;AAQL,EAAA,KAAA,CAAA,SAAA,CAAM,UAAN,GAAwB,YAAO;AAC/B,QAAA,CAAA,GAAO,KAAM,MAAb;;AAMD,WAAA,CAAA,CAAA,MAAA,EAEM,CAAA,GAAA,CAAA,CAAP,MAAO;;AACL,WAAK,CAAgB,CAAA,UAAhB,CAA4B,KAA5B,CAA4B,CAA5B,EACL;AAA4B,IAAA,SADvB,CAAL;AAEA,GAZA;;AAcE,SAAA,KAAA;CAxIW,CAyIX,WAzIW,CAAA,C,CA2If;AACF;AAlGA;AAoGA;;;AACA,IAAA,KAAA;AAAA;AAAA,UAAA,MAAA,EAAA;AACA,EAAA,SAAA,CAAA,KAAA,EAAA,MAAA,CAAA;;AACA,WAAA,KAAA,CAAA,IAAA,EAAA;AACA,WAAA,MAAA,CAAA,IAAA,CAAA,IAAA,EAAA,mBAAA,EAAA,IAAA,EAAA,YAAA,CAAA,CAAA,EAAA,IAAA,UAAA,CAAA,IAAA,CAAA,KAAA,CAAA,OAAA,EAAA,IAAA,CAAA,KAAA,CAAA,KAAA,IAAA;AAAoB;;AAClB,EAAA,KAAA,CAAA,SAAA,CAAY,WAAZ,GAAkC,YAAA;AAChC;AAMD,WAAA,IAAA;AAED,GATA;;AAUE,EAAA,KAAA,CAAA,SAAA,CAAA,KAAA,GAAA,UAAA,KAAA,EAAgC,KAAhC,EAAgC;AAChC;AACD;AAED;AACE;AACA;AACA,WAAA,KAAA,MAAA,CAAA,KAAA,CAAA,KAAA,EAAA,KAAA,CAAA;AACA,GARA;;AASA,SAAA,KAAA;CAvBJ,CAwBI,KAxBJ,CAAA;;AAyBE,SAAC,qBAAD,CAAC,cAAD,EAAC,cAAD,EAAC,QAAD,EAAC;AACH,MAAA,aAAC,GAAA,cAAA,CAAA,QAAA,CAAD;AAvBoB,MAAK,aAuBxB,GAAA,cAAA,CAAA,QAAA,CAvBmB,CAsBjB,CAGH;AAKE;AACA;AACA;AACA;;AACA,SAAA,KAAA,CAAA,aAAA,EAAA,aAAA,CAAA,GAAA,aAAA,GAAA,aAAA;AACA;;AACA,OAAA,SAAA,qBAAA,CAAA,KAAA,EAAA;AACA;AACD,SAAA,CAAA,EAAA,KAAA,YAAA,WAAA,IAAA,KAAA,CAAA,KAAA,CAAA,OAAA,CAAA;AAED","sourcesContent":["import { invariant } from \"../../utilities/globals/index.js\";\nimport type { OptimisticDependencyFunction } from \"optimism\";\nimport { dep } from \"optimism\";\nimport { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\n\nimport type {\n  StoreValue,\n  StoreObject,\n  Reference,\n} from \"../../utilities/index.js\";\nimport {\n  isReference,\n  makeReference,\n  DeepMerger,\n  maybeDeepFreeze,\n  canUseWeakMap,\n  isNonNullObject,\n} from \"../../utilities/index.js\";\nimport type { NormalizedCache, NormalizedCacheObject } from \"./types.js\";\nimport { hasOwn, fieldNameFromStoreName } from \"./helpers.js\";\nimport type { Policies, StorageType } from \"./policies.js\";\nimport type { Cache } from \"../core/types/Cache.js\";\nimport type {\n  SafeReadonly,\n  Modifier,\n  Modifiers,\n  ReadFieldOptions,\n  ToReferenceFunction,\n  CanReadFunction,\n  InvalidateModifier,\n  DeleteModifier,\n  ModifierDetails,\n} from \"../core/types/common.js\";\n\nconst DELETE: DeleteModifier = Object.create(null);\nconst delModifier: Modifier<any> = () => DELETE;\nconst INVALIDATE: InvalidateModifier = Object.create(null);\n\nexport abstract class EntityStore implements NormalizedCache {\n  protected data: NormalizedCacheObject = Object.create(null);\n\n  constructor(\n    public readonly policies: Policies,\n    public readonly group: CacheGroup\n  ) {}\n\n  public abstract addLayer(\n    layerId: string,\n    replay: (layer: EntityStore) => any\n  ): Layer;\n\n  public abstract removeLayer(layerId: string): EntityStore;\n\n  // Although the EntityStore class is abstract, it contains concrete\n  // implementations of the various NormalizedCache interface methods that\n  // are inherited by the Root and Layer subclasses.\n\n  public toObject(): NormalizedCacheObject {\n    return { ...this.data };\n  }\n\n  public has(dataId: string): boolean {\n    return this.lookup(dataId, true) !== void 0;\n  }\n\n  public get(dataId: string, fieldName: string): StoreValue {\n    this.group.depend(dataId, fieldName);\n    if (hasOwn.call(this.data, dataId)) {\n      const storeObject = this.data[dataId];\n      if (storeObject && hasOwn.call(storeObject, fieldName)) {\n        return storeObject[fieldName];\n      }\n    }\n    if (\n      fieldName === \"__typename\" &&\n      hasOwn.call(this.policies.rootTypenamesById, dataId)\n    ) {\n      return this.policies.rootTypenamesById[dataId];\n    }\n    if (this instanceof Layer) {\n      return this.parent.get(dataId, fieldName);\n    }\n  }\n\n  protected lookup(\n    dataId: string,\n    dependOnExistence?: boolean\n  ): StoreObject | undefined {\n    // The has method (above) calls lookup with dependOnExistence = true, so\n    // that it can later be invalidated when we add or remove a StoreObject for\n    // this dataId. Any consumer who cares about the contents of the StoreObject\n    // should not rely on this dependency, since the contents could change\n    // without the object being added or removed.\n    if (dependOnExistence) this.group.depend(dataId, \"__exists\");\n\n    if (hasOwn.call(this.data, dataId)) {\n      return this.data[dataId];\n    }\n\n    if (this instanceof Layer) {\n      return this.parent.lookup(dataId, dependOnExistence);\n    }\n\n    if (this.policies.rootTypenamesById[dataId]) {\n      return Object.create(null);\n    }\n  }\n\n  public merge(older: string | StoreObject, newer: StoreObject | string): void {\n    let dataId: string | undefined;\n\n    // Convert unexpected references to ID strings.\n    if (isReference(older)) older = older.__ref;\n    if (isReference(newer)) newer = newer.__ref;\n\n    const existing: StoreObject | undefined =\n      typeof older === \"string\" ? this.lookup((dataId = older)) : older;\n\n    const incoming: StoreObject | undefined =\n      typeof newer === \"string\" ? this.lookup((dataId = newer)) : newer;\n\n    // If newer was a string ID, but that ID was not defined in this store,\n    // then there are no fields to be merged, so we're done.\n    if (!incoming) return;\n\n    invariant(typeof dataId === \"string\", \"store.merge expects a string ID\");\n\n    const merged: StoreObject = new DeepMerger(storeObjectReconciler).merge(\n      existing,\n      incoming\n    );\n\n    // Even if merged === existing, existing may have come from a lower\n    // layer, so we always need to set this.data[dataId] on this level.\n    this.data[dataId] = merged;\n\n    if (merged !== existing) {\n      delete this.refs[dataId];\n      if (this.group.caching) {\n        const fieldsToDirty: Record<string, 1> = Object.create(null);\n\n        // If we added a new StoreObject where there was previously none, dirty\n        // anything that depended on the existence of this dataId, such as the\n        // EntityStore#has method.\n        if (!existing) fieldsToDirty.__exists = 1;\n\n        // Now invalidate dependents who called getFieldValue for any fields\n        // that are changing as a result of this merge.\n        Object.keys(incoming).forEach((storeFieldName) => {\n          if (\n            !existing ||\n            existing[storeFieldName] !== merged[storeFieldName]\n          ) {\n            // Always dirty the full storeFieldName, which may include\n            // serialized arguments following the fieldName prefix.\n            fieldsToDirty[storeFieldName] = 1;\n\n            // Also dirty fieldNameFromStoreName(storeFieldName) if it's\n            // different from storeFieldName and this field does not have\n            // keyArgs configured, because that means the cache can't make\n            // any assumptions about how field values with the same field\n            // name but different arguments might be interrelated, so it\n            // must err on the side of invalidating all field values that\n            // share the same short fieldName, regardless of arguments.\n            const fieldName = fieldNameFromStoreName(storeFieldName);\n            if (\n              fieldName !== storeFieldName &&\n              !this.policies.hasKeyArgs(merged.__typename, fieldName)\n            ) {\n              fieldsToDirty[fieldName] = 1;\n            }\n\n            // If merged[storeFieldName] has become undefined, and this is the\n            // Root layer, actually delete the property from the merged object,\n            // which is guaranteed to have been created fresh in this method.\n            if (merged[storeFieldName] === void 0 && !(this instanceof Layer)) {\n              delete merged[storeFieldName];\n            }\n          }\n        });\n\n        if (\n          fieldsToDirty.__typename &&\n          !(existing && existing.__typename) &&\n          // Since we return default root __typename strings\n          // automatically from store.get, we don't need to dirty the\n          // ROOT_QUERY.__typename field if merged.__typename is equal\n          // to the default string (usually \"Query\").\n          this.policies.rootTypenamesById[dataId] === merged.__typename\n        ) {\n          delete fieldsToDirty.__typename;\n        }\n\n        Object.keys(fieldsToDirty).forEach((fieldName) =>\n          this.group.dirty(dataId as string, fieldName)\n        );\n      }\n    }\n  }\n\n  public modify(\n    dataId: string,\n    fields: Modifier<any> | Modifiers<Record<string, any>>\n  ): boolean {\n    const storeObject = this.lookup(dataId);\n\n    if (storeObject) {\n      const changedFields: Record<string, any> = Object.create(null);\n      let needToMerge = false;\n      let allDeleted = true;\n\n      const sharedDetails = {\n        DELETE,\n        INVALIDATE,\n        isReference,\n        toReference: this.toReference,\n        canRead: this.canRead,\n        readField: <V = StoreValue>(\n          fieldNameOrOptions: string | ReadFieldOptions,\n          from?: StoreObject | Reference\n        ) =>\n          this.policies.readField<V>(\n            typeof fieldNameOrOptions === \"string\" ?\n              {\n                fieldName: fieldNameOrOptions,\n                from: from || makeReference(dataId),\n              }\n            : fieldNameOrOptions,\n            { store: this }\n          ),\n      } satisfies Partial<ModifierDetails>;\n\n      Object.keys(storeObject).forEach((storeFieldName) => {\n        const fieldName = fieldNameFromStoreName(storeFieldName);\n        let fieldValue = storeObject[storeFieldName];\n        if (fieldValue === void 0) return;\n        const modify: Modifier<StoreValue> | undefined =\n          typeof fields === \"function\" ? fields : (\n            fields[storeFieldName] || fields[fieldName]\n          );\n        if (modify) {\n          let newValue =\n            modify === delModifier ? DELETE : (\n              modify(maybeDeepFreeze(fieldValue), {\n                ...sharedDetails,\n                fieldName,\n                storeFieldName,\n                storage: this.getStorage(dataId, storeFieldName),\n              })\n            );\n          if (newValue === INVALIDATE) {\n            this.group.dirty(dataId, storeFieldName);\n          } else {\n            if (newValue === DELETE) newValue = void 0;\n            if (newValue !== fieldValue) {\n              changedFields[storeFieldName] = newValue;\n              needToMerge = true;\n              fieldValue = newValue;\n\n              if (__DEV__) {\n                const checkReference = (ref: Reference) => {\n                  if (this.lookup(ref.__ref) === undefined) {\n                    invariant.warn(\n                      \"cache.modify: You are trying to write a Reference that is not part of the store: %o\\n\" +\n                        \"Please make sure to set the `mergeIntoStore` parameter to `true` when creating a Reference that is not part of the store yet:\\n\" +\n                        \"`toReference(object, true)`\",\n                      ref\n                    );\n                    return true;\n                  }\n                };\n                if (isReference(newValue)) {\n                  checkReference(newValue);\n                } else if (Array.isArray(newValue)) {\n                  // Warn about writing \"mixed\" arrays of Reference and non-Reference objects\n                  let seenReference: boolean = false;\n                  let someNonReference: unknown;\n                  for (const value of newValue) {\n                    if (isReference(value)) {\n                      seenReference = true;\n                      if (checkReference(value)) break;\n                    } else {\n                      // Do not warn on primitive values, since those could never be represented\n                      // by a reference. This is a valid (albeit uncommon) use case.\n                      if (typeof value === \"object\" && !!value) {\n                        const [id] = this.policies.identify(value);\n                        // check if object could even be referenced, otherwise we are not interested in it for this warning\n                        if (id) {\n                          someNonReference = value;\n                        }\n                      }\n                    }\n                    if (seenReference && someNonReference !== undefined) {\n                      invariant.warn(\n                        \"cache.modify: Writing an array with a mix of both References and Objects will not result in the Objects being normalized correctly.\\n\" +\n                          \"Please convert the object instance %o to a Reference before writing it to the cache by calling `toReference(object, true)`.\",\n                        someNonReference\n                      );\n                      break;\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n        if (fieldValue !== void 0) {\n          allDeleted = false;\n        }\n      });\n\n      if (needToMerge) {\n        this.merge(dataId, changedFields);\n\n        if (allDeleted) {\n          if (this instanceof Layer) {\n            this.data[dataId] = void 0;\n          } else {\n            delete this.data[dataId];\n          }\n          this.group.dirty(dataId, \"__exists\");\n        }\n\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  // If called with only one argument, removes the entire entity\n  // identified by dataId. If called with a fieldName as well, removes all\n  // fields of that entity whose names match fieldName according to the\n  // fieldNameFromStoreName helper function. If called with a fieldName\n  // and variables, removes all fields of that entity whose names match fieldName\n  // and whose arguments when cached exactly match the variables passed.\n  public delete(\n    dataId: string,\n    fieldName?: string,\n    args?: Record<string, any>\n  ) {\n    const storeObject = this.lookup(dataId);\n    if (storeObject) {\n      const typename = this.getFieldValue<string>(storeObject, \"__typename\");\n      const storeFieldName =\n        fieldName && args ?\n          this.policies.getStoreFieldName({ typename, fieldName, args })\n        : fieldName;\n      return this.modify(\n        dataId,\n        storeFieldName ?\n          {\n            [storeFieldName]: delModifier,\n          }\n        : delModifier\n      );\n    }\n    return false;\n  }\n\n  public evict(options: Cache.EvictOptions, limit: EntityStore): boolean {\n    let evicted = false;\n    if (options.id) {\n      if (hasOwn.call(this.data, options.id)) {\n        evicted = this.delete(options.id, options.fieldName, options.args);\n      }\n      if (this instanceof Layer && this !== limit) {\n        evicted = this.parent.evict(options, limit) || evicted;\n      }\n      // Always invalidate the field to trigger rereading of watched\n      // queries, even if no cache data was modified by the eviction,\n      // because queries may depend on computed fields with custom read\n      // functions, whose values are not stored in the EntityStore.\n      if (options.fieldName || evicted) {\n        this.group.dirty(options.id, options.fieldName || \"__exists\");\n      }\n    }\n    return evicted;\n  }\n\n  public clear(): void {\n    this.replace(null);\n  }\n\n  public extract(): NormalizedCacheObject {\n    const obj = this.toObject();\n    const extraRootIds: string[] = [];\n    this.getRootIdSet().forEach((id) => {\n      if (!hasOwn.call(this.policies.rootTypenamesById, id)) {\n        extraRootIds.push(id);\n      }\n    });\n    if (extraRootIds.length) {\n      obj.__META = { extraRootIds: extraRootIds.sort() };\n    }\n    return obj;\n  }\n\n  public replace(newData: NormalizedCacheObject | null): void {\n    Object.keys(this.data).forEach((dataId) => {\n      if (!(newData && hasOwn.call(newData, dataId))) {\n        this.delete(dataId);\n      }\n    });\n    if (newData) {\n      const { __META, ...rest } = newData;\n      Object.keys(rest).forEach((dataId) => {\n        this.merge(dataId, rest[dataId] as StoreObject);\n      });\n      if (__META) {\n        __META.extraRootIds.forEach(this.retain, this);\n      }\n    }\n  }\n\n  public abstract getStorage(\n    idOrObj: string | StoreObject,\n    ...storeFieldNames: (string | number)[]\n  ): StorageType;\n\n  // Maps root entity IDs to the number of times they have been retained, minus\n  // the number of times they have been released. Retained entities keep other\n  // entities they reference (even indirectly) from being garbage collected.\n  private rootIds: {\n    [rootId: string]: number;\n  } = Object.create(null);\n\n  public retain(rootId: string): number {\n    return (this.rootIds[rootId] = (this.rootIds[rootId] || 0) + 1);\n  }\n\n  public release(rootId: string): number {\n    if (this.rootIds[rootId] > 0) {\n      const count = --this.rootIds[rootId];\n      if (!count) delete this.rootIds[rootId];\n      return count;\n    }\n    return 0;\n  }\n\n  // Return a Set<string> of all the ID strings that have been retained by\n  // this layer/root *and* any layers/roots beneath it.\n  public getRootIdSet(ids = new Set<string>()) {\n    Object.keys(this.rootIds).forEach(ids.add, ids);\n    if (this instanceof Layer) {\n      this.parent.getRootIdSet(ids);\n    } else {\n      // Official singleton IDs like ROOT_QUERY and ROOT_MUTATION are\n      // always considered roots for garbage collection, regardless of\n      // their retainment counts in this.rootIds.\n      Object.keys(this.policies.rootTypenamesById).forEach(ids.add, ids);\n    }\n    return ids;\n  }\n\n  // The goal of garbage collection is to remove IDs from the Root layer of the\n  // store that are no longer reachable starting from any IDs that have been\n  // explicitly retained (see retain and release, above). Returns an array of\n  // dataId strings that were removed from the store.\n  public gc() {\n    const ids = this.getRootIdSet();\n    const snapshot = this.toObject();\n    ids.forEach((id) => {\n      if (hasOwn.call(snapshot, id)) {\n        // Because we are iterating over an ECMAScript Set, the IDs we add here\n        // will be visited in later iterations of the forEach loop only if they\n        // were not previously contained by the Set.\n        Object.keys(this.findChildRefIds(id)).forEach(ids.add, ids);\n        // By removing IDs from the snapshot object here, we protect them from\n        // getting removed from the root store layer below.\n        delete snapshot[id];\n      }\n    });\n    const idsToRemove = Object.keys(snapshot);\n    if (idsToRemove.length) {\n      let root: EntityStore = this;\n      while (root instanceof Layer) root = root.parent;\n      idsToRemove.forEach((id) => root.delete(id));\n    }\n    return idsToRemove;\n  }\n\n  // Lazily tracks { __ref: <dataId> } strings contained by this.data[dataId].\n  private refs: {\n    [dataId: string]: Record<string, true>;\n  } = Object.create(null);\n\n  public findChildRefIds(dataId: string): Record<string, true> {\n    if (!hasOwn.call(this.refs, dataId)) {\n      const found = (this.refs[dataId] = Object.create(null));\n      const root = this.data[dataId];\n      if (!root) return found;\n\n      const workSet = new Set<Record<string | number, any>>([root]);\n      // Within the store, only arrays and objects can contain child entity\n      // references, so we can prune the traversal using this predicate:\n      workSet.forEach((obj) => {\n        if (isReference(obj)) {\n          found[obj.__ref] = true;\n          // In rare cases, a { __ref } Reference object may have other fields.\n          // This often indicates a mismerging of References with StoreObjects,\n          // but garbage collection should not be fooled by a stray __ref\n          // property in a StoreObject (ignoring all the other fields just\n          // because the StoreObject looks like a Reference). To avoid this\n          // premature termination of findChildRefIds recursion, we fall through\n          // to the code below, which will handle any other properties of obj.\n        }\n        if (isNonNullObject(obj)) {\n          Object.keys(obj).forEach((key) => {\n            const child = obj[key];\n            // No need to add primitive values to the workSet, since they cannot\n            // contain reference objects.\n            if (isNonNullObject(child)) {\n              workSet.add(child);\n            }\n          });\n        }\n      });\n    }\n    return this.refs[dataId];\n  }\n\n  // Used to compute cache keys specific to this.group.\n  public makeCacheKey(...args: any[]): object;\n  public makeCacheKey() {\n    return this.group.keyMaker.lookupArray(arguments);\n  }\n\n  // Bound function that can be passed around to provide easy access to fields\n  // of Reference objects as well as ordinary objects.\n  public getFieldValue = <T = StoreValue>(\n    objectOrReference: StoreObject | Reference | undefined,\n    storeFieldName: string\n  ) =>\n    maybeDeepFreeze(\n      isReference(objectOrReference) ?\n        this.get(objectOrReference.__ref, storeFieldName)\n      : objectOrReference && objectOrReference[storeFieldName]\n    ) as SafeReadonly<T>;\n\n  // Returns true for non-normalized StoreObjects and non-dangling\n  // References, indicating that readField(name, objOrRef) has a chance of\n  // working. Useful for filtering out dangling references from lists.\n  public canRead: CanReadFunction = (objOrRef) => {\n    return isReference(objOrRef) ?\n        this.has(objOrRef.__ref)\n      : typeof objOrRef === \"object\";\n  };\n\n  // Bound function that converts an id or an object with a __typename and\n  // primary key fields to a Reference object. If called with a Reference object,\n  // that same Reference object is returned. Pass true for mergeIntoStore to persist\n  // an object into the store.\n  public toReference: ToReferenceFunction = (objOrIdOrRef, mergeIntoStore) => {\n    if (typeof objOrIdOrRef === \"string\") {\n      return makeReference(objOrIdOrRef);\n    }\n\n    if (isReference(objOrIdOrRef)) {\n      return objOrIdOrRef;\n    }\n\n    const [id] = this.policies.identify(objOrIdOrRef);\n\n    if (id) {\n      const ref = makeReference(id);\n      if (mergeIntoStore) {\n        this.merge(id, objOrIdOrRef);\n      }\n      return ref;\n    }\n  };\n}\n\nexport type FieldValueGetter = EntityStore[\"getFieldValue\"];\n\n// A single CacheGroup represents a set of one or more EntityStore objects,\n// typically the Root store in a CacheGroup by itself, and all active Layer\n// stores in a group together. A single EntityStore object belongs to only\n// one CacheGroup, store.group. The CacheGroup is responsible for tracking\n// dependencies, so store.group is helpful for generating unique keys for\n// cached results that need to be invalidated when/if those dependencies\n// change. If we used the EntityStore objects themselves as cache keys (that\n// is, store rather than store.group), the cache would become unnecessarily\n// fragmented by all the different Layer objects. Instead, the CacheGroup\n// approach allows all optimistic Layer objects in the same linked list to\n// belong to one CacheGroup, with the non-optimistic Root object belonging\n// to another CacheGroup, allowing resultCaching dependencies to be tracked\n// separately for optimistic and non-optimistic entity data.\nclass CacheGroup {\n  private d: OptimisticDependencyFunction<string> | null = null;\n\n  // Used by the EntityStore#makeCacheKey method to compute cache keys\n  // specific to this CacheGroup.\n  public keyMaker!: Trie<object>;\n\n  constructor(\n    public readonly caching: boolean,\n    private parent: CacheGroup | null = null\n  ) {\n    this.resetCaching();\n  }\n\n  public resetCaching() {\n    this.d = this.caching ? dep<string>() : null;\n    this.keyMaker = new Trie(canUseWeakMap);\n  }\n\n  public depend(dataId: string, storeFieldName: string) {\n    if (this.d) {\n      this.d(makeDepKey(dataId, storeFieldName));\n      const fieldName = fieldNameFromStoreName(storeFieldName);\n      if (fieldName !== storeFieldName) {\n        // Fields with arguments that contribute extra identifying\n        // information to the fieldName (thus forming the storeFieldName)\n        // depend not only on the full storeFieldName but also on the\n        // short fieldName, so the field can be invalidated using either\n        // level of specificity.\n        this.d(makeDepKey(dataId, fieldName));\n      }\n      if (this.parent) {\n        this.parent.depend(dataId, storeFieldName);\n      }\n    }\n  }\n\n  public dirty(dataId: string, storeFieldName: string) {\n    if (this.d) {\n      this.d.dirty(\n        makeDepKey(dataId, storeFieldName),\n        // When storeFieldName === \"__exists\", that means the entity identified\n        // by dataId has either disappeared from the cache or was newly added,\n        // so the result caching system would do well to \"forget everything it\n        // knows\" about that object. To achieve that kind of invalidation, we\n        // not only dirty the associated result cache entry, but also remove it\n        // completely from the dependency graph. For the optimism implementation\n        // details, see https://github.com/benjamn/optimism/pull/195.\n        storeFieldName === \"__exists\" ? \"forget\" : \"setDirty\"\n      );\n    }\n  }\n}\n\nfunction makeDepKey(dataId: string, storeFieldName: string) {\n  // Since field names cannot have '#' characters in them, this method\n  // of joining the field name and the ID should be unambiguous, and much\n  // cheaper than JSON.stringify([dataId, fieldName]).\n  return storeFieldName + \"#\" + dataId;\n}\n\nexport function maybeDependOnExistenceOfEntity(\n  store: NormalizedCache,\n  entityId: string\n) {\n  if (supportsResultCaching(store)) {\n    // We use this pseudo-field __exists elsewhere in the EntityStore code to\n    // represent changes in the existence of the entity object identified by\n    // entityId. This dependency gets reliably dirtied whenever an object with\n    // this ID is deleted (or newly created) within this group, so any result\n    // cache entries (for example, StoreReader#executeSelectionSet results) that\n    // depend on __exists for this entityId will get dirtied as well, leading to\n    // the eventual recomputation (instead of reuse) of those result objects the\n    // next time someone reads them from the cache.\n    store.group.depend(entityId, \"__exists\");\n  }\n}\n\nexport namespace EntityStore {\n  // Refer to this class as EntityStore.Root outside this namespace.\n  export class Root extends EntityStore {\n    constructor({\n      policies,\n      resultCaching = true,\n      seed,\n    }: {\n      policies: Policies;\n      resultCaching?: boolean;\n      seed?: NormalizedCacheObject;\n    }) {\n      super(policies, new CacheGroup(resultCaching));\n      if (seed) this.replace(seed);\n    }\n\n    public readonly stump = new Stump(this);\n\n    public addLayer(\n      layerId: string,\n      replay: (layer: EntityStore) => any\n    ): Layer {\n      // Adding an optimistic Layer on top of the Root actually adds the Layer\n      // on top of the Stump, so the Stump always comes between the Root and\n      // any Layer objects that we've added.\n      return this.stump.addLayer(layerId, replay);\n    }\n\n    public removeLayer(): Root {\n      // Never remove the root layer.\n      return this;\n    }\n\n    public readonly storageTrie = new Trie<StorageType>(canUseWeakMap);\n    public getStorage(): StorageType {\n      return this.storageTrie.lookupArray(arguments);\n    }\n  }\n}\n\n// Not exported, since all Layer instances are created by the addLayer method\n// of the EntityStore.Root class.\nclass Layer extends EntityStore {\n  constructor(\n    public readonly id: string,\n    public readonly parent: EntityStore,\n    public readonly replay: (layer: EntityStore) => any,\n    public readonly group: CacheGroup\n  ) {\n    super(parent.policies, group);\n    replay(this);\n  }\n\n  public addLayer(layerId: string, replay: (layer: EntityStore) => any): Layer {\n    return new Layer(layerId, this, replay, this.group);\n  }\n\n  public removeLayer(layerId: string): EntityStore {\n    // Remove all instances of the given id, not just the first one.\n    const parent = this.parent.removeLayer(layerId);\n\n    if (layerId === this.id) {\n      if (this.group.caching) {\n        // Dirty every ID we're removing. Technically we might be able to avoid\n        // dirtying fields that have values in higher layers, but we don't have\n        // easy access to higher layers here, and we're about to recreate those\n        // layers anyway (see parent.addLayer below).\n        Object.keys(this.data).forEach((dataId) => {\n          const ownStoreObject = this.data[dataId];\n          const parentStoreObject = parent[\"lookup\"](dataId);\n          if (!parentStoreObject) {\n            // The StoreObject identified by dataId was defined in this layer\n            // but will be undefined in the parent layer, so we can delete the\n            // whole entity using this.delete(dataId). Since we're about to\n            // throw this layer away, the only goal of this deletion is to dirty\n            // the removed fields.\n            this.delete(dataId);\n          } else if (!ownStoreObject) {\n            // This layer had an entry for dataId but it was undefined, which\n            // means the entity was deleted in this layer, and it's about to\n            // become undeleted when we remove this layer, so we need to dirty\n            // all fields that are about to be reexposed.\n            this.group.dirty(dataId, \"__exists\");\n            Object.keys(parentStoreObject).forEach((storeFieldName) => {\n              this.group.dirty(dataId, storeFieldName);\n            });\n          } else if (ownStoreObject !== parentStoreObject) {\n            // If ownStoreObject is not exactly the same as parentStoreObject,\n            // dirty any fields whose values will change as a result of this\n            // removal.\n            Object.keys(ownStoreObject).forEach((storeFieldName) => {\n              if (\n                !equal(\n                  ownStoreObject[storeFieldName],\n                  parentStoreObject[storeFieldName]\n                )\n              ) {\n                this.group.dirty(dataId, storeFieldName);\n              }\n            });\n          }\n        });\n      }\n\n      return parent;\n    }\n\n    // No changes are necessary if the parent chain remains identical.\n    if (parent === this.parent) return this;\n\n    // Recreate this layer on top of the new parent.\n    return parent.addLayer(this.id, this.replay);\n  }\n\n  public toObject(): NormalizedCacheObject {\n    return {\n      ...this.parent.toObject(),\n      ...this.data,\n    };\n  }\n\n  public findChildRefIds(dataId: string): Record<string, true> {\n    const fromParent = this.parent.findChildRefIds(dataId);\n    return hasOwn.call(this.data, dataId) ?\n        {\n          ...fromParent,\n          ...super.findChildRefIds(dataId),\n        }\n      : fromParent;\n  }\n\n  public getStorage(): StorageType {\n    let p: EntityStore = this.parent;\n    while ((p as Layer).parent) p = (p as Layer).parent;\n    return p.getStorage.apply(\n      p,\n      // @ts-expect-error\n      arguments\n    );\n  }\n}\n\n// Represents a Layer permanently installed just above the Root, which allows\n// reading optimistically (and registering optimistic dependencies) even when\n// no optimistic layers are currently active. The stump.group CacheGroup object\n// is shared by any/all Layer objects added on top of the Stump.\nclass Stump extends Layer {\n  constructor(root: EntityStore.Root) {\n    super(\n      \"EntityStore.Stump\",\n      root,\n      () => {},\n      new CacheGroup(root.group.caching, root.group)\n    );\n  }\n\n  public removeLayer() {\n    // Never remove the Stump layer.\n    return this;\n  }\n\n  public merge(older: string | StoreObject, newer: string | StoreObject) {\n    // We never want to write any data into the Stump, so we forward any merge\n    // calls to the Root instead. Another option here would be to throw an\n    // exception, but the toReference(object, true) function can sometimes\n    // trigger Stump writes (which used to be Root writes, before the Stump\n    // concept was introduced).\n    return this.parent.merge(older, newer);\n  }\n}\n\nfunction storeObjectReconciler(\n  existingObject: StoreObject,\n  incomingObject: StoreObject,\n  property: string | number\n): StoreValue {\n  const existingValue = existingObject[property];\n  const incomingValue = incomingObject[property];\n  // Wherever there is a key collision, prefer the incoming value, unless\n  // it is deeply equal to the existing value. It's worth checking deep\n  // equality here (even though blindly returning incoming would be\n  // logically correct) because preserving the referential identity of\n  // existing data can prevent needless rereading and rerendering.\n  return equal(existingValue, incomingValue) ? existingValue : incomingValue;\n}\n\nexport function supportsResultCaching(store: any): store is EntityStore {\n  // When result caching is disabled, store.depend will be null.\n  return !!(store instanceof EntityStore && store.group.caching);\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}